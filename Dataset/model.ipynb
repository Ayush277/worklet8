{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1633a154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ mX_missing columns added and saved to 'with_mx_missing.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# STEP 1: Load your dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# STEP 2: Identify delinquency columns\n",
    "delinquency_cols = [f\"m{i}\" for i in range(1, 38)]\n",
    "\n",
    "# STEP 3: Create mX_missing columns\n",
    "for col in delinquency_cols:\n",
    "    df[f\"{col}_missing\"] = (df[col] == -1).astype(int)\n",
    "\n",
    "# STEP 4: Retain all columns, reorder so mX and mX_missing are together\n",
    "other_cols = [col for col in df.columns if col not in sum([[c, f\"{c}_missing\"] for c in delinquency_cols], [])]\n",
    "ordered_cols = []\n",
    "for col in delinquency_cols:\n",
    "    ordered_cols.append(col)\n",
    "    ordered_cols.append(f\"{col}_missing\")\n",
    "df = df[other_cols + ordered_cols]\n",
    "\n",
    "# STEP 5: Save the updated DataFrame\n",
    "df.to_csv(\"with_mx_missing.csv\", index=False)\n",
    "print(\"✅ mX_missing columns added and saved to 'with_mx_missing.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa61f66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>source</th>\n",
       "      <th>financial_institution</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>unpaid_principal_bal</th>\n",
       "      <th>Loan_Term</th>\n",
       "      <th>origination_date</th>\n",
       "      <th>first_payment_date</th>\n",
       "      <th>loan_to_value</th>\n",
       "      <th>number_of_borrowers</th>\n",
       "      <th>...</th>\n",
       "      <th>m33</th>\n",
       "      <th>m33_missing</th>\n",
       "      <th>m34</th>\n",
       "      <th>m34_missing</th>\n",
       "      <th>m35</th>\n",
       "      <th>m35_missing</th>\n",
       "      <th>m36</th>\n",
       "      <th>m36_missing</th>\n",
       "      <th>m37</th>\n",
       "      <th>m37_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.680000e+11</td>\n",
       "      <td>Z</td>\n",
       "      <td>Turner, Baldwin and Rhodes</td>\n",
       "      <td>4.250</td>\n",
       "      <td>214000</td>\n",
       "      <td>12</td>\n",
       "      <td>01-03-2012</td>\n",
       "      <td>May-12</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.730000e+11</td>\n",
       "      <td>Y</td>\n",
       "      <td>Swanson, Newton and Miller</td>\n",
       "      <td>4.875</td>\n",
       "      <td>144000</td>\n",
       "      <td>24</td>\n",
       "      <td>01-01-2012</td>\n",
       "      <td>Mar-12</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.430000e+11</td>\n",
       "      <td>Z</td>\n",
       "      <td>Thornton-Davis</td>\n",
       "      <td>3.250</td>\n",
       "      <td>366000</td>\n",
       "      <td>12</td>\n",
       "      <td>01-01-2012</td>\n",
       "      <td>Mar-12</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.010000e+11</td>\n",
       "      <td>X</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>4.750</td>\n",
       "      <td>135000</td>\n",
       "      <td>12</td>\n",
       "      <td>01-02-2012</td>\n",
       "      <td>Apr-12</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.740000e+11</td>\n",
       "      <td>X</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>4.750</td>\n",
       "      <td>124000</td>\n",
       "      <td>12</td>\n",
       "      <td>01-02-2012</td>\n",
       "      <td>Apr-12</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_id source       financial_institution  interest_rate  \\\n",
       "0  2.680000e+11      Z  Turner, Baldwin and Rhodes          4.250   \n",
       "1  6.730000e+11      Y  Swanson, Newton and Miller          4.875   \n",
       "2  7.430000e+11      Z              Thornton-Davis          3.250   \n",
       "3  6.010000e+11      X                       OTHER          4.750   \n",
       "4  2.740000e+11      X                       OTHER          4.750   \n",
       "\n",
       "   unpaid_principal_bal  Loan_Term origination_date first_payment_date  \\\n",
       "0                214000         12       01-03-2012             May-12   \n",
       "1                144000         24       01-01-2012             Mar-12   \n",
       "2                366000         12       01-01-2012             Mar-12   \n",
       "3                135000         12       01-02-2012             Apr-12   \n",
       "4                124000         12       01-02-2012             Apr-12   \n",
       "\n",
       "   loan_to_value  number_of_borrowers  ...  m33  m33_missing m34  m34_missing  \\\n",
       "0             95                    1  ...   -1            1  -1            1   \n",
       "1             72                    1  ...   -1            1  -1            1   \n",
       "2             49                    1  ...   -1            1  -1            1   \n",
       "3             46                    2  ...   -1            1  -1            1   \n",
       "4             80                    1  ...   -1            1  -1            1   \n",
       "\n",
       "   m35  m35_missing m36 m36_missing m37 m37_missing  \n",
       "0   -1            1  -1           1  -1           1  \n",
       "1   -1            1  -1           1  -1           1  \n",
       "2   -1            1  -1           1  -1           1  \n",
       "3   -1            1  -1           1  -1           1  \n",
       "4   -1            1  -1           1  -1           1  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train_new.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6cfc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loan_id source       financial_institution  interest_rate  unpaid_principal_bal  Loan_Term origination_date first_payment_date  loan_to_value  number_of_borrowers  debt_to_income_ratio  borrower_credit_score loan_purpose  insurance_percent  co-borrower_credit_score  insurance_type          Occupation  Borrower_State EducationLevel MaritalStatus  Age  Gender EmploymentStatus  NumberOfDependents  Annual Income  m1  m1_missing  m2  m2_missing  m3  m3_missing  m4  m4_missing  m5  m5_missing  m6  m6_missing  m7  m7_missing  m8  m8_missing  m9  m9_missing  m10  m10_missing  m11  m11_missing  m12  m12_missing  m13  m13_missing  m14  m14_missing  m15  m15_missing  m16  m16_missing  m17  m17_missing  m18  m18_missing  m19  m19_missing  m20  m20_missing  m21  m21_missing  m22  m22_missing  m23  m23_missing  m24  m24_missing  m25  m25_missing  m26  m26_missing  m27  m27_missing  m28  m28_missing  m29  m29_missing  m30  m30_missing  m31  m31_missing  m32  m32_missing  m33  m33_missing  \\\n",
      "0  2.680000e+11      Z  Turner, Baldwin and Rhodes          4.250                214000         12       01-03-2012             May-12             95                    1                    22                    694          C86                 30                         0               0      loader reciever             SD    High School       Married   45   Other       Unemployed                   1    9727.272727   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   \n",
      "1  6.730000e+11      Y  Swanson, Newton and Miller          4.875                144000         24       01-01-2012             Mar-12             72                    1                    44                    697          B12                  0                         0               0       home caregiver             IL    High School       Married   38   Other    Self-Employed                   0    3272.727273   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0    0            0    0            0    1            0    1            0    0            0    0            0    0            0    0            0    0            0    1            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   \n",
      "2  7.430000e+11      Z              Thornton-Davis          3.250                366000         12       01-01-2012             Mar-12             49                    1                    33                    780          B12                  0                         0               0  Service technician              NJ            PhD        Single   47  Female    Self-Employed                   1   11090.909090   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   \n",
      "3  6.010000e+11      X                       OTHER          4.750                135000         12       01-02-2012             Apr-12             46                    2                    44                    633          B12                  0                       638               0  Literacy Specialist             RI    High School       Married   58    Male         Employed                   0    3068.181818   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   \n",
      "4  2.740000e+11      X                       OTHER          4.750                124000         12       01-02-2012             Apr-12             80                    1                    43                    681          C86                  0                         0               0              Manager             GA     Bachelor's        Single   37    Male         Employed                   0    2883.720930   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   \n",
      "\n",
      "   m34  m34_missing  m35  m35_missing  m36  m36_missing  m37  m37_missing  \n",
      "0   -1            1   -1            1   -1            1   -1            1  \n",
      "1   -1            1   -1            1   -1            1   -1            1  \n",
      "2   -1            1   -1            1   -1            1   -1            1  \n",
      "3   -1            1   -1            1   -1            1   -1            1  \n",
      "4   -1            1   -1            1   -1            1   -1            1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set Pandas to display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# If you want to set a wider display in the console or notebook\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Now, when you print df.head(), all columns will be shown\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1029a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116058 entries, 0 to 116057\n",
      "Data columns (total 99 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   loan_id                   116058 non-null  float64\n",
      " 1   source                    116058 non-null  object \n",
      " 2   financial_institution     116058 non-null  object \n",
      " 3   interest_rate             116058 non-null  float64\n",
      " 4   unpaid_principal_bal      116058 non-null  int64  \n",
      " 5   Loan_Term                 116058 non-null  int64  \n",
      " 6   origination_date          116058 non-null  object \n",
      " 7   first_payment_date        116058 non-null  object \n",
      " 8   loan_to_value             116058 non-null  int64  \n",
      " 9   number_of_borrowers       116058 non-null  int64  \n",
      " 10  debt_to_income_ratio      116058 non-null  int64  \n",
      " 11  borrower_credit_score     116058 non-null  int64  \n",
      " 12  loan_purpose              116058 non-null  object \n",
      " 13  insurance_percent         116058 non-null  int64  \n",
      " 14  co-borrower_credit_score  116058 non-null  int64  \n",
      " 15  insurance_type            116058 non-null  int64  \n",
      " 16  Occupation                116058 non-null  object \n",
      " 17  Borrower_State            116058 non-null  object \n",
      " 18  EducationLevel            116058 non-null  object \n",
      " 19  MaritalStatus             116058 non-null  object \n",
      " 20  Age                       116058 non-null  int64  \n",
      " 21  Gender                    116058 non-null  object \n",
      " 22  EmploymentStatus          116058 non-null  object \n",
      " 23  NumberOfDependents        116058 non-null  int64  \n",
      " 24  Annual Income             116058 non-null  float64\n",
      " 25  m1                        116058 non-null  int64  \n",
      " 26  m1_missing                116058 non-null  int64  \n",
      " 27  m2                        116058 non-null  int64  \n",
      " 28  m2_missing                116058 non-null  int64  \n",
      " 29  m3                        116058 non-null  int64  \n",
      " 30  m3_missing                116058 non-null  int64  \n",
      " 31  m4                        116058 non-null  int64  \n",
      " 32  m4_missing                116058 non-null  int64  \n",
      " 33  m5                        116058 non-null  int64  \n",
      " 34  m5_missing                116058 non-null  int64  \n",
      " 35  m6                        116058 non-null  int64  \n",
      " 36  m6_missing                116058 non-null  int64  \n",
      " 37  m7                        116058 non-null  int64  \n",
      " 38  m7_missing                116058 non-null  int64  \n",
      " 39  m8                        116058 non-null  int64  \n",
      " 40  m8_missing                116058 non-null  int64  \n",
      " 41  m9                        116058 non-null  int64  \n",
      " 42  m9_missing                116058 non-null  int64  \n",
      " 43  m10                       116058 non-null  int64  \n",
      " 44  m10_missing               116058 non-null  int64  \n",
      " 45  m11                       116058 non-null  int64  \n",
      " 46  m11_missing               116058 non-null  int64  \n",
      " 47  m12                       116058 non-null  int64  \n",
      " 48  m12_missing               116058 non-null  int64  \n",
      " 49  m13                       116058 non-null  int64  \n",
      " 50  m13_missing               116058 non-null  int64  \n",
      " 51  m14                       116058 non-null  int64  \n",
      " 52  m14_missing               116058 non-null  int64  \n",
      " 53  m15                       116058 non-null  int64  \n",
      " 54  m15_missing               116058 non-null  int64  \n",
      " 55  m16                       116058 non-null  int64  \n",
      " 56  m16_missing               116058 non-null  int64  \n",
      " 57  m17                       116058 non-null  int64  \n",
      " 58  m17_missing               116058 non-null  int64  \n",
      " 59  m18                       116058 non-null  int64  \n",
      " 60  m18_missing               116058 non-null  int64  \n",
      " 61  m19                       116058 non-null  int64  \n",
      " 62  m19_missing               116058 non-null  int64  \n",
      " 63  m20                       116058 non-null  int64  \n",
      " 64  m20_missing               116058 non-null  int64  \n",
      " 65  m21                       116058 non-null  int64  \n",
      " 66  m21_missing               116058 non-null  int64  \n",
      " 67  m22                       116058 non-null  int64  \n",
      " 68  m22_missing               116058 non-null  int64  \n",
      " 69  m23                       116058 non-null  int64  \n",
      " 70  m23_missing               116058 non-null  int64  \n",
      " 71  m24                       116058 non-null  int64  \n",
      " 72  m24_missing               116058 non-null  int64  \n",
      " 73  m25                       116058 non-null  int64  \n",
      " 74  m25_missing               116058 non-null  int64  \n",
      " 75  m26                       116058 non-null  int64  \n",
      " 76  m26_missing               116058 non-null  int64  \n",
      " 77  m27                       116058 non-null  int64  \n",
      " 78  m27_missing               116058 non-null  int64  \n",
      " 79  m28                       116058 non-null  int64  \n",
      " 80  m28_missing               116058 non-null  int64  \n",
      " 81  m29                       116058 non-null  int64  \n",
      " 82  m29_missing               116058 non-null  int64  \n",
      " 83  m30                       116058 non-null  int64  \n",
      " 84  m30_missing               116058 non-null  int64  \n",
      " 85  m31                       116058 non-null  int64  \n",
      " 86  m31_missing               116058 non-null  int64  \n",
      " 87  m32                       116058 non-null  int64  \n",
      " 88  m32_missing               116058 non-null  int64  \n",
      " 89  m33                       116058 non-null  int64  \n",
      " 90  m33_missing               116058 non-null  int64  \n",
      " 91  m34                       116058 non-null  int64  \n",
      " 92  m34_missing               116058 non-null  int64  \n",
      " 93  m35                       116058 non-null  int64  \n",
      " 94  m35_missing               116058 non-null  int64  \n",
      " 95  m36                       116058 non-null  int64  \n",
      " 96  m36_missing               116058 non-null  int64  \n",
      " 97  m37                       116058 non-null  int64  \n",
      " 98  m37_missing               116058 non-null  int64  \n",
      "dtypes: float64(3), int64(85), object(11)\n",
      "memory usage: 87.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65ecd286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116058, 99)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef76714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>unpaid_principal_bal</th>\n",
       "      <th>Loan_Term</th>\n",
       "      <th>loan_to_value</th>\n",
       "      <th>number_of_borrowers</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>borrower_credit_score</th>\n",
       "      <th>insurance_percent</th>\n",
       "      <th>co-borrower_credit_score</th>\n",
       "      <th>insurance_type</th>\n",
       "      <th>Age</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>m1</th>\n",
       "      <th>m1_missing</th>\n",
       "      <th>m2</th>\n",
       "      <th>m2_missing</th>\n",
       "      <th>m3</th>\n",
       "      <th>m3_missing</th>\n",
       "      <th>m4</th>\n",
       "      <th>m4_missing</th>\n",
       "      <th>m5</th>\n",
       "      <th>m5_missing</th>\n",
       "      <th>m6</th>\n",
       "      <th>m6_missing</th>\n",
       "      <th>m7</th>\n",
       "      <th>m7_missing</th>\n",
       "      <th>m8</th>\n",
       "      <th>m8_missing</th>\n",
       "      <th>m9</th>\n",
       "      <th>m9_missing</th>\n",
       "      <th>m10</th>\n",
       "      <th>m10_missing</th>\n",
       "      <th>m11</th>\n",
       "      <th>m11_missing</th>\n",
       "      <th>m12</th>\n",
       "      <th>m12_missing</th>\n",
       "      <th>m13</th>\n",
       "      <th>m13_missing</th>\n",
       "      <th>m14</th>\n",
       "      <th>m14_missing</th>\n",
       "      <th>m15</th>\n",
       "      <th>m15_missing</th>\n",
       "      <th>m16</th>\n",
       "      <th>m16_missing</th>\n",
       "      <th>m17</th>\n",
       "      <th>m17_missing</th>\n",
       "      <th>m18</th>\n",
       "      <th>m18_missing</th>\n",
       "      <th>m19</th>\n",
       "      <th>m19_missing</th>\n",
       "      <th>m20</th>\n",
       "      <th>m20_missing</th>\n",
       "      <th>m21</th>\n",
       "      <th>m21_missing</th>\n",
       "      <th>m22</th>\n",
       "      <th>m22_missing</th>\n",
       "      <th>m23</th>\n",
       "      <th>m23_missing</th>\n",
       "      <th>m24</th>\n",
       "      <th>m24_missing</th>\n",
       "      <th>m25</th>\n",
       "      <th>m25_missing</th>\n",
       "      <th>m26</th>\n",
       "      <th>m26_missing</th>\n",
       "      <th>m27</th>\n",
       "      <th>m27_missing</th>\n",
       "      <th>m28</th>\n",
       "      <th>m28_missing</th>\n",
       "      <th>m29</th>\n",
       "      <th>m29_missing</th>\n",
       "      <th>m30</th>\n",
       "      <th>m30_missing</th>\n",
       "      <th>m31</th>\n",
       "      <th>m31_missing</th>\n",
       "      <th>m32</th>\n",
       "      <th>m32_missing</th>\n",
       "      <th>m33</th>\n",
       "      <th>m33_missing</th>\n",
       "      <th>m34</th>\n",
       "      <th>m34_missing</th>\n",
       "      <th>m35</th>\n",
       "      <th>m35_missing</th>\n",
       "      <th>m36</th>\n",
       "      <th>m36_missing</th>\n",
       "      <th>m37</th>\n",
       "      <th>m37_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.160580e+05</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>1.160580e+05</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.0</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.0</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.0</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.0</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.0</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.0</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.0</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "      <td>116058.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.494154e+11</td>\n",
       "      <td>3.868961</td>\n",
       "      <td>2.082262e+05</td>\n",
       "      <td>20.999225</td>\n",
       "      <td>67.431939</td>\n",
       "      <td>1.593186</td>\n",
       "      <td>30.742293</td>\n",
       "      <td>769.926778</td>\n",
       "      <td>2.786288</td>\n",
       "      <td>459.611565</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>39.701287</td>\n",
       "      <td>1.528253</td>\n",
       "      <td>7674.774034</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.164961</td>\n",
       "      <td>0.166675</td>\n",
       "      <td>-0.165142</td>\n",
       "      <td>0.166675</td>\n",
       "      <td>-0.164495</td>\n",
       "      <td>0.166675</td>\n",
       "      <td>-0.164737</td>\n",
       "      <td>0.166675</td>\n",
       "      <td>-0.165098</td>\n",
       "      <td>0.166675</td>\n",
       "      <td>-0.166675</td>\n",
       "      <td>0.166675</td>\n",
       "      <td>-0.201279</td>\n",
       "      <td>0.333351</td>\n",
       "      <td>-0.200882</td>\n",
       "      <td>0.333351</td>\n",
       "      <td>-0.198711</td>\n",
       "      <td>0.333351</td>\n",
       "      <td>-0.198720</td>\n",
       "      <td>0.333351</td>\n",
       "      <td>-0.200891</td>\n",
       "      <td>0.333351</td>\n",
       "      <td>-0.200512</td>\n",
       "      <td>0.333351</td>\n",
       "      <td>-0.399309</td>\n",
       "      <td>0.500026</td>\n",
       "      <td>-0.398878</td>\n",
       "      <td>0.500026</td>\n",
       "      <td>-0.400386</td>\n",
       "      <td>0.500026</td>\n",
       "      <td>-0.400196</td>\n",
       "      <td>0.500026</td>\n",
       "      <td>-0.399025</td>\n",
       "      <td>0.500026</td>\n",
       "      <td>-0.400688</td>\n",
       "      <td>0.500026</td>\n",
       "      <td>-0.600889</td>\n",
       "      <td>0.666701</td>\n",
       "      <td>-0.600743</td>\n",
       "      <td>0.666701</td>\n",
       "      <td>-0.600855</td>\n",
       "      <td>0.666701</td>\n",
       "      <td>-0.598511</td>\n",
       "      <td>0.666701</td>\n",
       "      <td>-0.599580</td>\n",
       "      <td>0.666701</td>\n",
       "      <td>-0.600622</td>\n",
       "      <td>0.666701</td>\n",
       "      <td>-0.799531</td>\n",
       "      <td>0.833376</td>\n",
       "      <td>-0.800134</td>\n",
       "      <td>0.833376</td>\n",
       "      <td>-0.799764</td>\n",
       "      <td>0.833376</td>\n",
       "      <td>-0.800496</td>\n",
       "      <td>0.833376</td>\n",
       "      <td>-0.800763</td>\n",
       "      <td>0.833376</td>\n",
       "      <td>-0.801048</td>\n",
       "      <td>0.833376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.597569e+11</td>\n",
       "      <td>0.461020</td>\n",
       "      <td>1.146851e+05</td>\n",
       "      <td>10.246692</td>\n",
       "      <td>17.291719</td>\n",
       "      <td>0.491242</td>\n",
       "      <td>9.730798</td>\n",
       "      <td>42.210706</td>\n",
       "      <td>8.096464</td>\n",
       "      <td>381.946926</td>\n",
       "      <td>0.056977</td>\n",
       "      <td>11.619786</td>\n",
       "      <td>1.389666</td>\n",
       "      <td>6373.272601</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376860</td>\n",
       "      <td>0.372687</td>\n",
       "      <td>0.377021</td>\n",
       "      <td>0.372687</td>\n",
       "      <td>0.378751</td>\n",
       "      <td>0.372687</td>\n",
       "      <td>0.378373</td>\n",
       "      <td>0.372687</td>\n",
       "      <td>0.376548</td>\n",
       "      <td>0.372687</td>\n",
       "      <td>0.372687</td>\n",
       "      <td>0.372687</td>\n",
       "      <td>0.651854</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>0.652280</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>0.654605</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>0.654596</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>0.652270</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>0.652678</td>\n",
       "      <td>0.471413</td>\n",
       "      <td>0.664303</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>0.664886</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>0.662843</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>0.663100</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>0.664688</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>0.609466</td>\n",
       "      <td>0.471394</td>\n",
       "      <td>0.609730</td>\n",
       "      <td>0.471394</td>\n",
       "      <td>0.609528</td>\n",
       "      <td>0.471394</td>\n",
       "      <td>0.613742</td>\n",
       "      <td>0.471394</td>\n",
       "      <td>0.611825</td>\n",
       "      <td>0.471394</td>\n",
       "      <td>0.609948</td>\n",
       "      <td>0.471394</td>\n",
       "      <td>0.477465</td>\n",
       "      <td>0.372641</td>\n",
       "      <td>0.475821</td>\n",
       "      <td>0.372641</td>\n",
       "      <td>0.476832</td>\n",
       "      <td>0.372641</td>\n",
       "      <td>0.474831</td>\n",
       "      <td>0.372641</td>\n",
       "      <td>0.474098</td>\n",
       "      <td>0.372641</td>\n",
       "      <td>0.473318</td>\n",
       "      <td>0.372641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+11</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.100000e+04</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>341.463415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.240000e+11</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>751.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3920.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.490000e+11</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>1.830000e+05</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>782.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6256.410256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.740000e+11</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>2.780000e+05</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>791.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9692.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+12</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>840.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>836.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>470000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loan_id  interest_rate  unpaid_principal_bal      Loan_Term  loan_to_value  number_of_borrowers  debt_to_income_ratio  borrower_credit_score  insurance_percent  co-borrower_credit_score  insurance_type            Age  NumberOfDependents  Annual Income             m1  m1_missing             m2  m2_missing             m3  m3_missing             m4  m4_missing             m5  m5_missing             m6  m6_missing             m7  m7_missing             m8     m8_missing             m9     m9_missing            m10    m10_missing            m11    m11_missing            m12    m12_missing            m13    m13_missing            m14    m14_missing            m15    m15_missing            m16    m16_missing            m17    m17_missing            m18    m18_missing            m19    m19_missing            m20    m20_missing            m21    m21_missing            m22    m22_missing            m23    m23_missing            m24    m24_missing            m25    m25_missing  \\\n",
       "count  1.160580e+05  116058.000000          1.160580e+05  116058.000000  116058.000000        116058.000000         116058.000000          116058.000000      116058.000000             116058.000000   116058.000000  116058.000000       116058.000000  116058.000000  116058.000000    116058.0  116058.000000    116058.0  116058.000000    116058.0  116058.000000    116058.0  116058.000000    116058.0  116058.000000    116058.0  116058.000000    116058.0  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000   \n",
       "mean   5.494154e+11       3.868961          2.082262e+05      20.999225      67.431939             1.593186             30.742293             769.926778           2.786288                459.611565        0.003257      39.701287            1.528253    7674.774034       0.003197         0.0       0.002059         0.0       0.001973         0.0       0.002180         0.0       0.003533         0.0       0.003421         0.0       0.004162         0.0      -0.164961       0.166675      -0.165142       0.166675      -0.164495       0.166675      -0.164737       0.166675      -0.165098       0.166675      -0.166675       0.166675      -0.201279       0.333351      -0.200882       0.333351      -0.198711       0.333351      -0.198720       0.333351      -0.200891       0.333351      -0.200512       0.333351      -0.399309       0.500026      -0.398878       0.500026      -0.400386       0.500026      -0.400196       0.500026      -0.399025       0.500026      -0.400688       0.500026   \n",
       "std    2.597569e+11       0.461020          1.146851e+05      10.246692      17.291719             0.491242              9.730798              42.210706           8.096464                381.946926        0.056977      11.619786            1.389666    6373.272601       0.063354         0.0       0.051391         0.0       0.055427         0.0       0.062161         0.0       0.082638         0.0       0.087553         0.0       0.100961         0.0       0.376860       0.372687       0.377021       0.372687       0.378751       0.372687       0.378373       0.372687       0.376548       0.372687       0.372687       0.372687       0.651854       0.471413       0.652280       0.471413       0.654605       0.471413       0.654596       0.471413       0.652270       0.471413       0.652678       0.471413       0.664303       0.500002       0.664886       0.500002       0.662843       0.500002       0.663100       0.500002       0.664688       0.500002       0.662433       0.500002   \n",
       "min    1.000000e+11       2.250000          1.100000e+04       6.000000       6.000000             1.000000              1.000000               0.000000           0.000000                  0.000000        0.000000      18.000000            0.000000     341.463415       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000   \n",
       "25%    3.240000e+11       3.500000          1.200000e+05      12.000000      57.000000             1.000000             23.000000             751.000000           0.000000                  0.000000        0.000000      31.000000            0.000000    3920.000000       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000   \n",
       "50%    5.490000e+11       3.875000          1.830000e+05      18.000000      72.000000             2.000000             31.000000             782.000000           0.000000                740.000000        0.000000      40.000000            1.000000    6256.410256       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000   \n",
       "75%    7.740000e+11       4.125000          2.780000e+05      30.000000      80.000000             2.000000             39.000000             800.000000           0.000000                791.000000        0.000000      48.000000            3.000000    9692.307692       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000         0.0       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000   \n",
       "max    1.000000e+12       6.750000          1.200000e+06      36.000000      97.000000             2.000000             64.000000             840.000000          40.000000                836.000000        1.000000      80.000000            5.000000  470000.000000       3.000000         0.0       4.000000         0.0       5.000000         0.0       6.000000         0.0       7.000000         0.0       8.000000         0.0       9.000000         0.0       6.000000       1.000000       7.000000       1.000000       8.000000       1.000000       8.000000       1.000000       7.000000       1.000000       0.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                 m26    m26_missing            m27    m27_missing            m28    m28_missing            m29    m29_missing            m30    m30_missing            m31    m31_missing            m32    m32_missing            m33    m33_missing            m34    m34_missing            m35    m35_missing            m36    m36_missing            m37    m37_missing  \n",
       "count  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  116058.000000  \n",
       "mean       -0.600889       0.666701      -0.600743       0.666701      -0.600855       0.666701      -0.598511       0.666701      -0.599580       0.666701      -0.600622       0.666701      -0.799531       0.833376      -0.800134       0.833376      -0.799764       0.833376      -0.800496       0.833376      -0.800763       0.833376      -0.801048       0.833376  \n",
       "std         0.609466       0.471394       0.609730       0.471394       0.609528       0.471394       0.613742       0.471394       0.611825       0.471394       0.609948       0.471394       0.477465       0.372641       0.475821       0.372641       0.476832       0.372641       0.474831       0.372641       0.474098       0.372641       0.473318       0.372641  \n",
       "min        -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000  \n",
       "25%        -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       0.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000  \n",
       "50%        -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000  \n",
       "75%         0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000      -1.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e75bb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_id                  0\n",
      "source                   0\n",
      "financial_institution    0\n",
      "interest_rate            0\n",
      "unpaid_principal_bal     0\n",
      "                        ..\n",
      "m35_missing              0\n",
      "m36                      0\n",
      "m36_missing              0\n",
      "m37                      0\n",
      "m37_missing              0\n",
      "Length: 99, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca554653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         False\n",
      "1         False\n",
      "2         False\n",
      "3         False\n",
      "4         False\n",
      "          ...  \n",
      "116053    False\n",
      "116054    False\n",
      "116055    False\n",
      "116056    False\n",
      "116057    False\n",
      "Length: 116058, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "duplicates = df.duplicated()\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd432872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [loan_id, source, financial_institution, interest_rate, unpaid_principal_bal, Loan_Term, origination_date, first_payment_date, loan_to_value, number_of_borrowers, debt_to_income_ratio, borrower_credit_score, loan_purpose, insurance_percent, co-borrower_credit_score, insurance_type, Occupation , Borrower_State, EducationLevel, MaritalStatus, Age, Gender, EmploymentStatus, NumberOfDependents, Annual Income, m1, m1_missing, m2, m2_missing, m3, m3_missing, m4, m4_missing, m5, m5_missing, m6, m6_missing, m7, m7_missing, m8, m8_missing, m9, m9_missing, m10, m10_missing, m11, m11_missing, m12, m12_missing, m13, m13_missing, m14, m14_missing, m15, m15_missing, m16, m16_missing, m17, m17_missing, m18, m18_missing, m19, m19_missing, m20, m20_missing, m21, m21_missing, m22, m22_missing, m23, m23_missing, m24, m24_missing, m25, m25_missing, m26, m26_missing, m27, m27_missing, m28, m28_missing, m29, m29_missing, m30, m30_missing, m31, m31_missing, m32, m32_missing, m33, m33_missing, m34, m34_missing, m35, m35_missing, m36, m36_missing, m37, m37_missing]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print(duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a11710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Other' 'Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "unique_genders = df['Gender'].unique()\n",
    "print(unique_genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17982148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z' 'Y' 'X']\n"
     ]
    }
   ],
   "source": [
    "unique_genders = df['source'].unique()\n",
    "print(unique_genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a3097ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "unique_genders = df['insurance_type'].unique()\n",
    "print(unique_genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c93ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C86' 'B12' 'A23']\n"
     ]
    }
   ],
   "source": [
    "unique_genders = df['loan_purpose'].unique()\n",
    "print(unique_genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cefcb091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loader reciever' 'home caregiver' 'Service technician ' ...\n",
      " 'Product Design pilot' 'Floorpersom' 'DNS']\n"
     ]
    }
   ],
   "source": [
    "unique_genders = df['Occupation '].unique()\n",
    "print(unique_genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0672fd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['May-12' 'Mar-12' 'Apr-12' 'Feb-12']\n"
     ]
    }
   ],
   "source": [
    "unique_genders = df['first_payment_date'].unique()\n",
    "print(unique_genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "785cf400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High School' 'PhD' \"Bachelor's\" \"Master's\" 'Doctorate']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_genders = df['EducationLevel'].unique()\n",
    "print(unique_genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75fdae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Turner, Baldwin and Rhodes' 'Swanson, Newton and Miller'\n",
      " 'Thornton-Davis' 'OTHER' 'Browning-Hart' 'Richardson Ltd'\n",
      " 'Edwards-Hoffman' 'Richards-Walters' 'Martinez, Duffy and Bird'\n",
      " 'Miller, Mcclure and Allen' 'Anderson-Taylor'\n",
      " 'Taylor, Hunt and Rodriguez' 'Nicholson Group' 'Cole, Brooks and Vincent'\n",
      " 'Sanchez, Hays and Wilkerson' 'Sanchez-Robinson' 'Suarez Inc'\n",
      " 'Romero, Woods and Johnson' 'Chapman-Mcmahon']\n"
     ]
    }
   ],
   "source": [
    "unique_genders = df['financial_institution'].unique()\n",
    "print(unique_genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047abbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loan_id source  interest_rate  unpaid_principal_bal  Loan_Term origination_date first_payment_date  loan_to_value  number_of_borrowers  debt_to_income_ratio  borrower_credit_score loan_purpose  insurance_percent  co-borrower_credit_score  insurance_type          Occupation  Borrower_State EducationLevel MaritalStatus  Age  Gender EmploymentStatus  NumberOfDependents  Annual Income  m1  m1_missing  m2  m2_missing  m3  m3_missing  m4  m4_missing  m5  m5_missing  m6  m6_missing  m7  m7_missing  m8  m8_missing  m9  m9_missing  m10  m10_missing  m11  m11_missing  m12  m12_missing  m13  m13_missing  m14  m14_missing  m15  m15_missing  m16  m16_missing  m17  m17_missing  m18  m18_missing  m19  m19_missing  m20  m20_missing  m21  m21_missing  m22  m22_missing  m23  m23_missing  m24  m24_missing  m25  m25_missing  m26  m26_missing  m27  m27_missing  m28  m28_missing  m29  m29_missing  m30  m30_missing  m31  m31_missing  m32  m32_missing  m33  m33_missing  m34  m34_missing  m35  \\\n",
      "0  2.680000e+11      Z          4.250                214000         12       01-03-2012             May-12             95                    1                    22                    694          C86                 30                         0               0      loader reciever             SD    High School       Married   45   Other       Unemployed                   1    9727.272727   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1   \n",
      "1  6.730000e+11      Y          4.875                144000         24       01-01-2012             Mar-12             72                    1                    44                    697          B12                  0                         0               0       home caregiver             IL    High School       Married   38   Other    Self-Employed                   0    3272.727273   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0    0            0    0            0    1            0    1            0    0            0    0            0    0            0    0            0    0            0    1            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1   \n",
      "2  7.430000e+11      Z          3.250                366000         12       01-01-2012             Mar-12             49                    1                    33                    780          B12                  0                         0               0  Service technician              NJ            PhD        Single   47  Female    Self-Employed                   1   11090.909090   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1   \n",
      "3  6.010000e+11      X          4.750                135000         12       01-02-2012             Apr-12             46                    2                    44                    633          B12                  0                       638               0  Literacy Specialist             RI    High School       Married   58    Male         Employed                   0    3068.181818   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1   \n",
      "4  2.740000e+11      X          4.750                124000         12       01-02-2012             Apr-12             80                    1                    43                    681          C86                  0                         0               0              Manager             GA     Bachelor's        Single   37    Male         Employed                   0    2883.720930   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1   \n",
      "\n",
      "   m35_missing  m36  m36_missing  m37  m37_missing  financial_institution_Browning-Hart  financial_institution_Chapman-Mcmahon  financial_institution_Cole, Brooks and Vincent  financial_institution_Edwards-Hoffman  financial_institution_Martinez, Duffy and Bird  financial_institution_Miller, Mcclure and Allen  financial_institution_Nicholson Group  financial_institution_OTHER  financial_institution_Richards-Walters  financial_institution_Richardson Ltd  financial_institution_Romero, Woods and Johnson  financial_institution_Sanchez, Hays and Wilkerson  financial_institution_Sanchez-Robinson  financial_institution_Suarez Inc  financial_institution_Swanson, Newton and Miller  financial_institution_Taylor, Hunt and Rodriguez  financial_institution_Thornton-Davis  financial_institution_Turner, Baldwin and Rhodes  \n",
      "0            1   -1            1   -1            1                                False                                  False                                           False                                  False                                           False                                            False                                  False                        False                                   False                                 False                                            False                                              False                                   False                             False                                             False                                             False                                 False                                              True  \n",
      "1            1   -1            1   -1            1                                False                                  False                                           False                                  False                                           False                                            False                                  False                        False                                   False                                 False                                            False                                              False                                   False                             False                                              True                                             False                                 False                                             False  \n",
      "2            1   -1            1   -1            1                                False                                  False                                           False                                  False                                           False                                            False                                  False                        False                                   False                                 False                                            False                                              False                                   False                             False                                             False                                             False                                  True                                             False  \n",
      "3            1   -1            1   -1            1                                False                                  False                                           False                                  False                                           False                                            False                                  False                         True                                   False                                 False                                            False                                              False                                   False                             False                                             False                                             False                                 False                                             False  \n",
      "4            1   -1            1   -1            1                                False                                  False                                           False                                  False                                           False                                            False                                  False                         True                                   False                                 False                                            False                                              False                                   False                             False                                             False                                             False                                 False                                             False  \n",
      "Original columns: Index(['loan_id', 'source', 'financial_institution', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'origination_date', 'first_payment_date', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'loan_purpose', 'insurance_percent', 'co-borrower_credit_score', 'insurance_type', 'Occupation ', 'Borrower_State', 'EducationLevel', 'MaritalStatus', 'Age', 'Gender', 'EmploymentStatus', 'NumberOfDependents', 'Annual Income', 'm1', 'm1_missing', 'm2', 'm2_missing', 'm3', 'm3_missing', 'm4', 'm4_missing', 'm5', 'm5_missing', 'm6', 'm6_missing', 'm7', 'm7_missing', 'm8', 'm8_missing', 'm9', 'm9_missing', 'm10', 'm10_missing', 'm11', 'm11_missing', 'm12', 'm12_missing', 'm13', 'm13_missing', 'm14', 'm14_missing', 'm15', 'm15_missing', 'm16', 'm16_missing', 'm17', 'm17_missing', 'm18', 'm18_missing', 'm19', 'm19_missing', 'm20', 'm20_missing', 'm21', 'm21_missing', 'm22', 'm22_missing', 'm23', 'm23_missing', 'm24', 'm24_missing', 'm25', 'm25_missing',\n",
      "       'm26', 'm26_missing', 'm27', 'm27_missing', 'm28', 'm28_missing', 'm29', 'm29_missing', 'm30', 'm30_missing', 'm31', 'm31_missing', 'm32', 'm32_missing', 'm33', 'm33_missing', 'm34', 'm34_missing', 'm35', 'm35_missing', 'm36', 'm36_missing', 'm37', 'm37_missing'],\n",
      "      dtype='object')\n",
      "New columns after encoding: Index(['loan_id', 'source', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'origination_date', 'first_payment_date', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio',\n",
      "       ...\n",
      "       'financial_institution_Richards-Walters', 'financial_institution_Richardson Ltd', 'financial_institution_Romero, Woods and Johnson', 'financial_institution_Sanchez, Hays and Wilkerson', 'financial_institution_Sanchez-Robinson', 'financial_institution_Suarez Inc', 'financial_institution_Swanson, Newton and Miller', 'financial_institution_Taylor, Hunt and Rodriguez', 'financial_institution_Thornton-Davis', 'financial_institution_Turner, Baldwin and Rhodes'], dtype='object', length=116)\n"
     ]
    }
   ],
   "source": [
    "# Financial Institution\n",
    "import pandas as pd\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "df_copy = pd.get_dummies(df_copy, columns=['financial_institution'], drop_first=True)\n",
    "\n",
    "print(df_copy.head())\n",
    "print(\"Original columns:\", df.columns)\n",
    "print(\"New columns after encoding:\", df_copy.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e50d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loan_id source       financial_institution  interest_rate  unpaid_principal_bal  Loan_Term origination_date first_payment_date  loan_to_value  number_of_borrowers  debt_to_income_ratio  borrower_credit_score  insurance_percent  co-borrower_credit_score  insurance_type          Occupation  Borrower_State EducationLevel MaritalStatus  Age  Gender EmploymentStatus  NumberOfDependents  Annual Income  m1  m1_missing  m2  m2_missing  m3  m3_missing  m4  m4_missing  m5  m5_missing  m6  m6_missing  m7  m7_missing  m8  m8_missing  m9  m9_missing  m10  m10_missing  m11  m11_missing  m12  m12_missing  m13  m13_missing  m14  m14_missing  m15  m15_missing  m16  m16_missing  m17  m17_missing  m18  m18_missing  m19  m19_missing  m20  m20_missing  m21  m21_missing  m22  m22_missing  m23  m23_missing  m24  m24_missing  m25  m25_missing  m26  m26_missing  m27  m27_missing  m28  m28_missing  m29  m29_missing  m30  m30_missing  m31  m31_missing  m32  m32_missing  m33  m33_missing  m34  \\\n",
      "0  2.680000e+11      Z  Turner, Baldwin and Rhodes          4.250                214000         12       01-03-2012             May-12             95                    1                    22                    694                 30                         0               0      loader reciever             SD    High School       Married   45   Other       Unemployed                   1    9727.272727   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1   \n",
      "1  6.730000e+11      Y  Swanson, Newton and Miller          4.875                144000         24       01-01-2012             Mar-12             72                    1                    44                    697                  0                         0               0       home caregiver             IL    High School       Married   38   Other    Self-Employed                   0    3272.727273   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0    0            0    0            0    1            0    1            0    0            0    0            0    0            0    0            0    0            0    1            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1   \n",
      "2  7.430000e+11      Z              Thornton-Davis          3.250                366000         12       01-01-2012             Mar-12             49                    1                    33                    780                  0                         0               0  Service technician              NJ            PhD        Single   47  Female    Self-Employed                   1   11090.909090   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1   \n",
      "3  6.010000e+11      X                       OTHER          4.750                135000         12       01-02-2012             Apr-12             46                    2                    44                    633                  0                       638               0  Literacy Specialist             RI    High School       Married   58    Male         Employed                   0    3068.181818   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1   \n",
      "4  2.740000e+11      X                       OTHER          4.750                124000         12       01-02-2012             Apr-12             80                    1                    43                    681                  0                         0               0              Manager             GA     Bachelor's        Single   37    Male         Employed                   0    2883.720930   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1   \n",
      "\n",
      "   m34_missing  m35  m35_missing  m36  m36_missing  m37  m37_missing  loan_purpose_B12  loan_purpose_C86  \n",
      "0            1   -1            1   -1            1   -1            1             False              True  \n",
      "1            1   -1            1   -1            1   -1            1              True             False  \n",
      "2            1   -1            1   -1            1   -1            1              True             False  \n",
      "3            1   -1            1   -1            1   -1            1              True             False  \n",
      "4            1   -1            1   -1            1   -1            1             False              True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_copy = df.copy()\n",
    "df_copy = pd.get_dummies(df_copy, columns=['loan_purpose'], drop_first=True)\n",
    "print(df_copy.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101ff463",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Make a fresh copy of your original DataFrame\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_copy = \u001b[43mdf\u001b[49m.copy()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# List all categorical columns you want to encode\u001b[39;00m\n\u001b[32m      7\u001b[39m categorical_cols = [\u001b[33m'\u001b[39m\u001b[33mfinancial_institution\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mloan_purpose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGender\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEmploymentStatus\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEducationLevel\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make a fresh copy of your original DataFrame\n",
    "df_copy = df.copy()\n",
    "\n",
    "# List all categorical columns you want to encode\n",
    "categorical_cols = ['financial_institution', 'loan_purpose', 'Gender', 'EmploymentStatus', 'EducationLevel']\n",
    "\n",
    "# One-hot encode all at once\n",
    "df_copy = pd.get_dummies(df_copy, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(df_copy.head())\n",
    "print(df_copy.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   origination_date_year  origination_date_month  origination_date_day  first_payment_date_year  first_payment_date_month  first_payment_date_day  days_to_first_payment\n",
      "0                   2012                       3                     1                     2012                         5                       1                     61\n",
      "1                   2012                       1                     1                     2012                         3                       1                     60\n",
      "2                   2012                       1                     1                     2012                         3                       1                     60\n",
      "3                   2012                       2                     1                     2012                         4                       1                     60\n",
      "4                   2012                       2                     1                     2012                         4                       1                     60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_copy['origination_date'] = pd.to_datetime(df_copy['origination_date'], dayfirst=True, errors='coerce')\n",
    "first_payment_str = df_copy['first_payment_date'].str.replace('-', ' ', regex=False)\n",
    "df_copy['first_payment_date'] = pd.to_datetime(first_payment_str, format='%b %y', errors='coerce')\n",
    "\n",
    "for col in ['origination_date', 'first_payment_date']:\n",
    "    df_copy[f'{col}_year'] = df_copy[col].dt.year\n",
    "    df_copy[f'{col}_month'] = df_copy[col].dt.month\n",
    "    df_copy[f'{col}_day'] = df_copy[col].dt.day\n",
    "\n",
    "df_copy['days_to_first_payment'] = (df_copy['first_payment_date'] - df_copy['origination_date']).dt.days\n",
    "\n",
    "print(df_copy[['origination_date_year', 'origination_date_month', 'origination_date_day',\n",
    "               'first_payment_date_year', 'first_payment_date_month', 'first_payment_date_day',\n",
    "               'days_to_first_payment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f806ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan_id', 'source', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'origination_date', 'first_payment_date', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'insurance_percent', 'co-borrower_credit_score', 'insurance_type', 'Occupation ', 'Borrower_State', 'EducationLevel', 'MaritalStatus', 'Age', 'NumberOfDependents', 'Annual Income', 'm1', 'm1_missing', 'm2', 'm2_missing', 'm3', 'm3_missing', 'm4', 'm4_missing', 'm5', 'm5_missing', 'm6', 'm6_missing', 'm7', 'm7_missing', 'm8', 'm8_missing', 'm9', 'm9_missing', 'm10', 'm10_missing', 'm11', 'm11_missing', 'm12', 'm12_missing', 'm13', 'm13_missing', 'm14', 'm14_missing', 'm15', 'm15_missing', 'm16', 'm16_missing', 'm17', 'm17_missing', 'm18', 'm18_missing', 'm19', 'm19_missing', 'm20', 'm20_missing', 'm21', 'm21_missing', 'm22', 'm22_missing', 'm23', 'm23_missing', 'm24', 'm24_missing', 'm25', 'm25_missing', 'm26', 'm26_missing', 'm27', 'm27_missing', 'm28', 'm28_missing', 'm29', 'm29_missing', 'm30', 'm30_missing', 'm31', 'm31_missing', 'm32', 'm32_missing', 'm33', 'm33_missing', 'm34', 'm34_missing', 'm35', 'm35_missing', 'm36', 'm36_missing', 'm37', 'm37_missing', 'financial_institution_Browning-Hart', 'financial_institution_Chapman-Mcmahon', 'financial_institution_Cole, Brooks and Vincent', 'financial_institution_Edwards-Hoffman', 'financial_institution_Martinez, Duffy and Bird', 'financial_institution_Miller, Mcclure and Allen', 'financial_institution_Nicholson Group', 'financial_institution_OTHER', 'financial_institution_Richards-Walters', 'financial_institution_Richardson Ltd', 'financial_institution_Romero, Woods and Johnson', 'financial_institution_Sanchez, Hays and Wilkerson', 'financial_institution_Sanchez-Robinson', 'financial_institution_Suarez Inc', 'financial_institution_Swanson, Newton and Miller', 'financial_institution_Taylor, Hunt and Rodriguez', 'financial_institution_Thornton-Davis', 'financial_institution_Turner, Baldwin and Rhodes', 'loan_purpose_B12', 'loan_purpose_C86', 'Gender_Male', 'Gender_Other', 'EmploymentStatus_Self-Employed', 'EmploymentStatus_Unemployed', 'origination_date_year', 'origination_date_month', 'origination_date_day', 'first_payment_date_year', 'first_payment_date_month', 'first_payment_date_day', 'days_to_first_payment']\n"
     ]
    }
   ],
   "source": [
    "print(df_copy.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35b51819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan_id', 'source', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'insurance_percent', 'co-borrower_credit_score', 'insurance_type', 'Occupation ', 'Borrower_State', 'MaritalStatus', 'Age', 'NumberOfDependents', 'Annual Income', 'm1', 'm1_missing', 'm2', 'm2_missing', 'm3', 'm3_missing', 'm4', 'm4_missing', 'm5', 'm5_missing', 'm6', 'm6_missing', 'm7', 'm7_missing', 'm8', 'm8_missing', 'm9', 'm9_missing', 'm10', 'm10_missing', 'm11', 'm11_missing', 'm12', 'm12_missing', 'm13', 'm13_missing', 'm14', 'm14_missing', 'm15', 'm15_missing', 'm16', 'm16_missing', 'm17', 'm17_missing', 'm18', 'm18_missing', 'm19', 'm19_missing', 'm20', 'm20_missing', 'm21', 'm21_missing', 'm22', 'm22_missing', 'm23', 'm23_missing', 'm24', 'm24_missing', 'm25', 'm25_missing', 'm26', 'm26_missing', 'm27', 'm27_missing', 'm28', 'm28_missing', 'm29', 'm29_missing', 'm30', 'm30_missing', 'm31', 'm31_missing', 'm32', 'm32_missing', 'm33', 'm33_missing', 'm34', 'm34_missing', 'm35', 'm35_missing', 'm36', 'm36_missing', 'm37', 'm37_missing', 'financial_institution_Browning-Hart', 'financial_institution_Chapman-Mcmahon', 'financial_institution_Cole, Brooks and Vincent', 'financial_institution_Edwards-Hoffman', 'financial_institution_Martinez, Duffy and Bird', 'financial_institution_Miller, Mcclure and Allen', 'financial_institution_Nicholson Group', 'financial_institution_OTHER', 'financial_institution_Richards-Walters', 'financial_institution_Richardson Ltd', 'financial_institution_Romero, Woods and Johnson', 'financial_institution_Sanchez, Hays and Wilkerson', 'financial_institution_Sanchez-Robinson', 'financial_institution_Suarez Inc', 'financial_institution_Swanson, Newton and Miller', 'financial_institution_Taylor, Hunt and Rodriguez', 'financial_institution_Thornton-Davis', 'financial_institution_Turner, Baldwin and Rhodes', 'loan_purpose_B12', 'loan_purpose_C86', 'Gender_Male', 'Gender_Other', 'EmploymentStatus_Self-Employed', 'EmploymentStatus_Unemployed', 'EducationLevel_Doctorate', 'EducationLevel_High School', \"EducationLevel_Master's\", 'EducationLevel_PhD', 'origination_date_year', 'origination_date_month', 'origination_date_day', 'first_payment_date_year', 'first_payment_date_month', 'first_payment_date_day', 'days_to_first_payment']\n"
     ]
    }
   ],
   "source": [
    "# Remove financial_institution if it exists\n",
    "if 'financial_institution' in df_copy.columns:\n",
    "    df_copy.drop(['financial_institution'], axis=1, inplace=True)\n",
    "\n",
    "if 'EducationLevel' in df_copy.columns:\n",
    "    df_copy.drop(['EducationLevel'], axis=1, inplace=True)\n",
    "\n",
    "# Remove origination_date and first_payment_date if they exist\n",
    "if 'origination_date' in df_copy.columns and 'first_payment_date' in df_copy.columns:\n",
    "    df_copy.drop(['origination_date', 'first_payment_date'], axis=1, inplace=True)\n",
    "\n",
    "if 'Gender' in df_copy.columns and 'EmploymentStatus' in df_copy.columns:\n",
    "    df_copy.drop(['Gender', 'EmploymentStatus'], axis=1, inplace=True)    \n",
    "\n",
    "# Print the updated column list to confirm\n",
    "print(list(df_copy.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0fa9517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan_id', 'source', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'insurance_percent', 'co-borrower_credit_score', 'insurance_type', 'Occupation ', 'Borrower_State', 'MaritalStatus', 'Age', 'NumberOfDependents', 'Annual Income', 'm1', 'm1_missing', 'm2', 'm2_missing', 'm3', 'm3_missing', 'm4', 'm4_missing', 'm5', 'm5_missing', 'm6', 'm6_missing', 'm7', 'm7_missing', 'm8', 'm8_missing', 'm9', 'm9_missing', 'm10', 'm10_missing', 'm11', 'm11_missing', 'm12', 'm12_missing', 'm13', 'm13_missing', 'm14', 'm14_missing', 'm15', 'm15_missing', 'm16', 'm16_missing', 'm17', 'm17_missing', 'm18', 'm18_missing', 'm19', 'm19_missing', 'm20', 'm20_missing', 'm21', 'm21_missing', 'm22', 'm22_missing', 'm23', 'm23_missing', 'm24', 'm24_missing', 'm25', 'm25_missing', 'm26', 'm26_missing', 'm27', 'm27_missing', 'm28', 'm28_missing', 'm29', 'm29_missing', 'm30', 'm30_missing', 'm31', 'm31_missing', 'm32', 'm32_missing', 'm33', 'm33_missing', 'm34', 'm34_missing', 'm35', 'm35_missing', 'm36', 'm36_missing', 'm37', 'm37_missing', 'financial_institution_Browning-Hart', 'financial_institution_Chapman-Mcmahon', 'financial_institution_Cole, Brooks and Vincent', 'financial_institution_Edwards-Hoffman', 'financial_institution_Martinez, Duffy and Bird', 'financial_institution_Miller, Mcclure and Allen', 'financial_institution_Nicholson Group', 'financial_institution_OTHER', 'financial_institution_Richards-Walters', 'financial_institution_Richardson Ltd', 'financial_institution_Romero, Woods and Johnson', 'financial_institution_Sanchez, Hays and Wilkerson', 'financial_institution_Sanchez-Robinson', 'financial_institution_Suarez Inc', 'financial_institution_Swanson, Newton and Miller', 'financial_institution_Taylor, Hunt and Rodriguez', 'financial_institution_Thornton-Davis', 'financial_institution_Turner, Baldwin and Rhodes', 'loan_purpose_B12', 'loan_purpose_C86', 'Gender_Male', 'Gender_Other', 'EmploymentStatus_Self-Employed', 'EmploymentStatus_Unemployed', 'EducationLevel_Doctorate', 'EducationLevel_High School', \"EducationLevel_Master's\", 'EducationLevel_PhD', 'origination_date_year', 'origination_date_month', 'origination_date_day', 'first_payment_date_year', 'first_payment_date_month', 'first_payment_date_day', 'days_to_first_payment']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_copy.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d57fb659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan_id', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'insurance_percent', 'co-borrower_credit_score', 'insurance_type', 'Occupation ', 'Borrower_State', 'Age', 'NumberOfDependents', 'Annual Income', 'm1', 'm1_missing', 'm2', 'm2_missing', 'm3', 'm3_missing', 'm4', 'm4_missing', 'm5', 'm5_missing', 'm6', 'm6_missing', 'm7', 'm7_missing', 'm8', 'm8_missing', 'm9', 'm9_missing', 'm10', 'm10_missing', 'm11', 'm11_missing', 'm12', 'm12_missing', 'm13', 'm13_missing', 'm14', 'm14_missing', 'm15', 'm15_missing', 'm16', 'm16_missing', 'm17', 'm17_missing', 'm18', 'm18_missing', 'm19', 'm19_missing', 'm20', 'm20_missing', 'm21', 'm21_missing', 'm22', 'm22_missing', 'm23', 'm23_missing', 'm24', 'm24_missing', 'm25', 'm25_missing', 'm26', 'm26_missing', 'm27', 'm27_missing', 'm28', 'm28_missing', 'm29', 'm29_missing', 'm30', 'm30_missing', 'm31', 'm31_missing', 'm32', 'm32_missing', 'm33', 'm33_missing', 'm34', 'm34_missing', 'm35', 'm35_missing', 'm36', 'm36_missing', 'm37', 'm37_missing', 'financial_institution_Browning-Hart', 'financial_institution_Chapman-Mcmahon', 'financial_institution_Cole, Brooks and Vincent', 'financial_institution_Edwards-Hoffman', 'financial_institution_Martinez, Duffy and Bird', 'financial_institution_Miller, Mcclure and Allen', 'financial_institution_Nicholson Group', 'financial_institution_OTHER', 'financial_institution_Richards-Walters', 'financial_institution_Richardson Ltd', 'financial_institution_Romero, Woods and Johnson', 'financial_institution_Sanchez, Hays and Wilkerson', 'financial_institution_Sanchez-Robinson', 'financial_institution_Suarez Inc', 'financial_institution_Swanson, Newton and Miller', 'financial_institution_Taylor, Hunt and Rodriguez', 'financial_institution_Thornton-Davis', 'financial_institution_Turner, Baldwin and Rhodes', 'loan_purpose_B12', 'loan_purpose_C86', 'Gender_Male', 'Gender_Other', 'EmploymentStatus_Self-Employed', 'EmploymentStatus_Unemployed', 'EducationLevel_Doctorate', 'EducationLevel_High School', \"EducationLevel_Master's\", 'EducationLevel_PhD', 'origination_date_year', 'origination_date_month', 'origination_date_day', 'first_payment_date_year', 'first_payment_date_month', 'first_payment_date_day', 'days_to_first_payment']\n"
     ]
    }
   ],
   "source": [
    "# Remove 'source' and 'MaritalStatus' columns from df_copy if they exist\n",
    "cols_to_drop = ['source', 'MaritalStatus']\n",
    "for col in cols_to_drop:\n",
    "    if col in df_copy.columns:\n",
    "        df_copy.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Print the updated columns to confirm\n",
    "print(list(df_copy.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ac9a89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loan_id  interest_rate  unpaid_principal_bal  Loan_Term  loan_to_value  number_of_borrowers  debt_to_income_ratio  borrower_credit_score  insurance_percent  co-borrower_credit_score  insurance_type          Occupation  Borrower_State  Age  NumberOfDependents  Annual Income  m1  m1_missing  m2  m2_missing  m3  m3_missing  m4  m4_missing  m5  m5_missing  m6  m6_missing  m7  m7_missing  m8  m8_missing  m9  m9_missing  m10  m10_missing  m11  m11_missing  m12  m12_missing  m13  m13_missing  m14  m14_missing  m15  m15_missing  m16  m16_missing  m17  m17_missing  m18  m18_missing  m19  m19_missing  m20  m20_missing  m21  m21_missing  m22  m22_missing  m23  m23_missing  m24  m24_missing  m25  m25_missing  m26  m26_missing  m27  m27_missing  m28  m28_missing  m29  m29_missing  m30  m30_missing  m31  m31_missing  m32  m32_missing  m33  m33_missing  m34  m34_missing  m35  m35_missing  m36  m36_missing  m37  m37_missing  financial_institution_Browning-Hart  \\\n",
      "0  2.680000e+11          4.250                214000         12             95                    1                    22                    694                 30                         0               0      loader reciever             SD   45                   1    9727.272727   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1                                False   \n",
      "1  6.730000e+11          4.875                144000         24             72                    1                    44                    697                  0                         0               0       home caregiver             IL   38                   0    3272.727273   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0    0            0    0            0    1            0    1            0    0            0    0            0    0            0    0            0    0            0    1            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1                                False   \n",
      "2  7.430000e+11          3.250                366000         12             49                    1                    33                    780                  0                         0               0  Service technician              NJ   47                   1   11090.909090   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1                                False   \n",
      "3  6.010000e+11          4.750                135000         12             46                    2                    44                    633                  0                       638               0  Literacy Specialist             RI   58                   0    3068.181818   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1                                False   \n",
      "4  2.740000e+11          4.750                124000         12             80                    1                    43                    681                  0                         0               0              Manager             GA   37                   0    2883.720930   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0   0           0    0            0    0            0    0            0    0            0   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1   -1            1                                False   \n",
      "\n",
      "   financial_institution_Chapman-Mcmahon  financial_institution_Cole, Brooks and Vincent  financial_institution_Edwards-Hoffman  financial_institution_Martinez, Duffy and Bird  financial_institution_Miller, Mcclure and Allen  financial_institution_Nicholson Group  financial_institution_OTHER  financial_institution_Richards-Walters  financial_institution_Richardson Ltd  financial_institution_Romero, Woods and Johnson  financial_institution_Sanchez, Hays and Wilkerson  financial_institution_Sanchez-Robinson  financial_institution_Suarez Inc  financial_institution_Swanson, Newton and Miller  financial_institution_Taylor, Hunt and Rodriguez  financial_institution_Thornton-Davis  financial_institution_Turner, Baldwin and Rhodes  loan_purpose_B12  loan_purpose_C86  Gender_Male  Gender_Other  EmploymentStatus_Self-Employed  EmploymentStatus_Unemployed  EducationLevel_Doctorate  EducationLevel_High School  EducationLevel_Master's  EducationLevel_PhD  origination_date_year  \\\n",
      "0                                  False                                           False                                  False                                           False                                            False                                  False                        False                                   False                                 False                                            False                                              False                                   False                             False                                             False                                             False                                 False                                              True             False              True        False          True                           False                         True                     False                        True                    False               False                   2012   \n",
      "1                                  False                                           False                                  False                                           False                                            False                                  False                        False                                   False                                 False                                            False                                              False                                   False                             False                                              True                                             False                                 False                                             False              True             False        False          True                            True                        False                     False                        True                    False               False                   2012   \n",
      "2                                  False                                           False                                  False                                           False                                            False                                  False                        False                                   False                                 False                                            False                                              False                                   False                             False                                             False                                             False                                  True                                             False              True             False        False         False                            True                        False                     False                       False                    False                True                   2012   \n",
      "3                                  False                                           False                                  False                                           False                                            False                                  False                         True                                   False                                 False                                            False                                              False                                   False                             False                                             False                                             False                                 False                                             False              True             False         True         False                           False                        False                     False                        True                    False               False                   2012   \n",
      "4                                  False                                           False                                  False                                           False                                            False                                  False                         True                                   False                                 False                                            False                                              False                                   False                             False                                             False                                             False                                 False                                             False             False              True         True         False                           False                        False                     False                       False                    False               False                   2012   \n",
      "\n",
      "   origination_date_month  origination_date_day  first_payment_date_year  first_payment_date_month  first_payment_date_day  days_to_first_payment  \n",
      "0                       3                     1                     2012                         5                       1                     61  \n",
      "1                       1                     1                     2012                         3                       1                     60  \n",
      "2                       1                     1                     2012                         3                       1                     60  \n",
      "3                       2                     1                     2012                         4                       1                     60  \n",
      "4                       2                     1                     2012                         4                       1                     60  \n"
     ]
    }
   ],
   "source": [
    "print(df_copy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bfd3fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame 'model' as a copy of 'df_copy'\n",
    "model = df_copy.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9614402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan_id', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'insurance_percent', 'co-borrower_credit_score', 'insurance_type', 'Occupation ', 'Borrower_State', 'Age', 'NumberOfDependents', 'Annual Income', 'm1', 'm1_missing', 'm2', 'm2_missing', 'm3', 'm3_missing', 'm4', 'm4_missing', 'm5', 'm5_missing', 'm6', 'm6_missing', 'm7', 'm7_missing', 'm8', 'm8_missing', 'm9', 'm9_missing', 'm10', 'm10_missing', 'm11', 'm11_missing', 'm12', 'm12_missing', 'm13', 'm13_missing', 'm14', 'm14_missing', 'm15', 'm15_missing', 'm16', 'm16_missing', 'm17', 'm17_missing', 'm18', 'm18_missing', 'm19', 'm19_missing', 'm20', 'm20_missing', 'm21', 'm21_missing', 'm22', 'm22_missing', 'm23', 'm23_missing', 'm24', 'm24_missing', 'm25', 'm25_missing', 'm26', 'm26_missing', 'm27', 'm27_missing', 'm28', 'm28_missing', 'm29', 'm29_missing', 'm30', 'm30_missing', 'm31', 'm31_missing', 'm32', 'm32_missing', 'm33', 'm33_missing', 'm34', 'm34_missing', 'm35', 'm35_missing', 'm36', 'm36_missing', 'm37', 'm37_missing', 'financial_institution_Browning-Hart', 'financial_institution_Chapman-Mcmahon', 'financial_institution_Cole, Brooks and Vincent', 'financial_institution_Edwards-Hoffman', 'financial_institution_Martinez, Duffy and Bird', 'financial_institution_Miller, Mcclure and Allen', 'financial_institution_Nicholson Group', 'financial_institution_OTHER', 'financial_institution_Richards-Walters', 'financial_institution_Richardson Ltd', 'financial_institution_Romero, Woods and Johnson', 'financial_institution_Sanchez, Hays and Wilkerson', 'financial_institution_Sanchez-Robinson', 'financial_institution_Suarez Inc', 'financial_institution_Swanson, Newton and Miller', 'financial_institution_Taylor, Hunt and Rodriguez', 'financial_institution_Thornton-Davis', 'financial_institution_Turner, Baldwin and Rhodes', 'loan_purpose_B12', 'loan_purpose_C86', 'Gender_Male', 'Gender_Other', 'EmploymentStatus_Self-Employed', 'EmploymentStatus_Unemployed', 'EducationLevel_Doctorate', 'EducationLevel_High School', \"EducationLevel_Master's\", 'EducationLevel_PhD', 'origination_date_year', 'origination_date_month', 'origination_date_day', 'first_payment_date_year', 'first_payment_date_month', 'first_payment_date_day', 'days_to_first_payment']\n"
     ]
    }
   ],
   "source": [
    "print(list(model.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab50b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you're working on a clean copy\n",
    "newmodel = df_copy.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53081b22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2437128,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Train model if valid samples exist\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     X = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     y = np.array(y)\n\u001b[32m     51\u001b[39m     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2437128,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Delinquency months (you can only predict up to m36 since m37 is last)\n",
    "months = list(range(1, 37))\n",
    "\n",
    "# Base features (make sure these columns exist in your dataset)\n",
    "static_cols = [\n",
    "    'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value',\n",
    "    'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score',\n",
    "    'insurance_percent', 'co-borrower_credit_score', 'insurance_type',\n",
    "    'Age', 'NumberOfDependents', 'Annual Income',\n",
    "]\n",
    "\n",
    "# Add one-hot encoded categorical columns\n",
    "for col in newmodel.columns:\n",
    "    if col.startswith(('financial_institution_', 'loan_purpose_', 'Gender_',\n",
    "                       'EmploymentStatus_', 'EducationLevel_')):\n",
    "        static_cols.append(col)\n",
    "\n",
    "# Prepare features and targets\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, row in newmodel.iterrows():\n",
    "    for t in months:\n",
    "        cur_m = f\"m{t}\"\n",
    "        next_m = f\"m{t+1}\"\n",
    "        next_m_missing = f\"m{t+1}_missing\"\n",
    "\n",
    "        # Skip if this prediction month is invalid\n",
    "        if next_m not in newmodel.columns:\n",
    "            continue\n",
    "        if row.get(next_m_missing, 1) == 1 or row.get(cur_m, -1) == -1 or row.get(next_m, -1) == -1:\n",
    "            continue\n",
    "\n",
    "        # Past payment history up to current month\n",
    "        m_features = [row.get(f\"m{i}\", -1) for i in range(1, t + 1)]\n",
    "        static_features = [row.get(feat, 0) for feat in static_cols]\n",
    "\n",
    "        X.append(m_features + static_features)\n",
    "        y.append(row[next_m])\n",
    "\n",
    "# Train model if valid samples exist\n",
    "if X:\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "else:\n",
    "    print(\"❌ No valid training samples. Check your mX/mX_missing values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc0878da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained successfully.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95    440505\n",
      "           1       0.10      0.00      0.00     46866\n",
      "           2       0.00      0.00      0.00        27\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.90    487426\n",
      "   macro avg       0.13      0.12      0.12    487426\n",
      "weighted avg       0.83      0.90      0.86    487426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# List of months for delinquency\n",
    "months = list(range(1, 37))\n",
    "\n",
    "# Base features (static loan + borrower features)\n",
    "static_cols = [\n",
    "    'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value',\n",
    "    'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score',\n",
    "    'insurance_percent', 'co-borrower_credit_score', 'insurance_type',\n",
    "    'Age', 'NumberOfDependents', 'Annual Income',\n",
    "]\n",
    "\n",
    "# Add one-hot encoded categorical feature columns\n",
    "for col in newmodel.columns:\n",
    "    if col.startswith(('financial_institution_', 'loan_purpose_', 'Gender_',\n",
    "                       'EmploymentStatus_', 'EducationLevel_')):\n",
    "        static_cols.append(col)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Loop through all rows in dataset\n",
    "for idx, row in newmodel.iterrows():\n",
    "    for t in months:\n",
    "        cur_m = f\"m{t}\"\n",
    "        next_m = f\"m{t+1}\"\n",
    "        next_m_missing = f\"m{t+1}_missing\"\n",
    "\n",
    "        # Skip if next month is invalid or current/next values are -1\n",
    "        if next_m not in newmodel.columns:\n",
    "            continue\n",
    "        if row.get(next_m_missing, 1) == 1 or row.get(cur_m, -1) == -1 or row.get(next_m, -1) == -1:\n",
    "            continue\n",
    "\n",
    "        # Get delinquency history m1 to mt\n",
    "        m_features = [row.get(f\"m{i}\", -1) for i in range(1, t + 1)]\n",
    "\n",
    "        # Pad with -1 to reach length 36 (max months)\n",
    "        m_features += [-1] * (36 - len(m_features))\n",
    "\n",
    "        # Get static features\n",
    "        static_features = [row.get(feat, 0) for feat in static_cols]\n",
    "\n",
    "        # Final feature vector\n",
    "        X.append(m_features + static_features)\n",
    "        y.append(row[next_m])\n",
    "\n",
    "# Convert to NumPy arrays and train model\n",
    "if X:\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"✅ Model trained successfully.\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "else:\n",
    "    print(\"❌ No valid training samples. Check mX/mX_missing logic.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f21370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you're working on a clean copy\n",
    "newm = df_copy.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8a39fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained successfully.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.58      0.73    440562\n",
      "           1       0.20      0.99      0.33     46864\n",
      "\n",
      "    accuracy                           0.62    487426\n",
      "   macro avg       0.60      0.78      0.53    487426\n",
      "weighted avg       0.92      0.62      0.69    487426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# List of months for delinquency\n",
    "months = list(range(1, 37))\n",
    "\n",
    "# Base features (static loan + borrower features)\n",
    "static_cols = [\n",
    "    'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value',\n",
    "    'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score',\n",
    "    'insurance_percent', 'co-borrower_credit_score', 'insurance_type',\n",
    "    'Age', 'NumberOfDependents', 'Annual Income',\n",
    "]\n",
    "\n",
    "# Add one-hot encoded categorical feature columns\n",
    "for col in newmodel.columns:\n",
    "    if col.startswith(('financial_institution_', 'loan_purpose_', 'Gender_',\n",
    "                       'EmploymentStatus_', 'EducationLevel_')):\n",
    "        static_cols.append(col)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Loop through all rows in dataset\n",
    "for idx, row in newm.iterrows():\n",
    "    for t in months:\n",
    "        cur_m = f\"m{t}\"\n",
    "        next_m = f\"m{t+1}\"\n",
    "        next_m_missing = f\"m{t+1}_missing\"\n",
    "\n",
    "        # Skip if next month is invalid or current/next values are -1\n",
    "        if next_m not in newmodel.columns:\n",
    "            continue\n",
    "        if row.get(next_m_missing, 1) == 1 or row.get(cur_m, -1) == -1 or row.get(next_m, -1) == -1:\n",
    "            continue\n",
    "\n",
    "        # Get delinquency history m1 to mt\n",
    "        m_features = [row.get(f\"m{i}\", -1) for i in range(1, t + 1)]\n",
    "\n",
    "        # Pad with -1 to reach length 36 (max months)\n",
    "        m_features += [-1] * (36 - len(m_features))\n",
    "\n",
    "        # Get static features\n",
    "        static_features = [row.get(feat, 0) for feat in static_cols]\n",
    "\n",
    "        # Final feature vector\n",
    "        X.append(m_features + static_features)\n",
    "        # Binary target: 0 = no delinquency, 1 = any delinquency\n",
    "        y.append(1 if row[next_m] > 0 else 0)\n",
    "\n",
    "# Convert to NumPy arrays and train model\n",
    "if X:\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        class_weight='balanced',\n",
    "        solver='saga',\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"✅ Model trained successfully.\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "else:\n",
    "    print(\"❌ No valid training samples. Check mX/mX_missing logic.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba163609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Feature  Coefficient  Abs_Coefficient\n",
      "12                                              m13     2.747436         2.747436\n",
      "11                                              m12    -0.298290         0.298290\n",
      "6                                                m7    -0.180871         0.180871\n",
      "1                                                m2     0.174433         0.174433\n",
      "3                                                m4     0.151705         0.151705\n",
      "..                                              ...          ...              ...\n",
      "14                                              m15    -0.000196         0.000196\n",
      "59  financial_institution_Romero, Woods and Johnson     0.000173         0.000173\n",
      "15                                              m16     0.000060         0.000060\n",
      "45                                   insurance_type     0.000025         0.000025\n",
      "16                                              m17     0.000016         0.000016\n",
      "\n",
      "[77 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define your static and one-hot encoded feature columns (as in your model)\n",
    "static_cols = [\n",
    "    'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value',\n",
    "    'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score',\n",
    "    'insurance_percent', 'co-borrower_credit_score', 'insurance_type',\n",
    "    'Age', 'NumberOfDependents', 'Annual Income',\n",
    "]\n",
    "\n",
    "# Add one-hot encoded categorical feature columns\n",
    "for col in newm.columns:\n",
    "    if col.startswith(('financial_institution_', 'loan_purpose_', 'Gender_',\n",
    "                       'EmploymentStatus_', 'EducationLevel_')):\n",
    "        static_cols.append(col)\n",
    "\n",
    "# 2. Build the full feature name list (delinquency history + statics)\n",
    "m_features = [f\"m{i}\" for i in range(1, 37)]\n",
    "all_feature_names = m_features + static_cols\n",
    "\n",
    "# 3. Get model coefficients (assume model is already trained)\n",
    "coefs = model.coef_[0]\n",
    "\n",
    "# 4. Create DataFrame for feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Coefficient': coefs,\n",
    "    'Abs_Coefficient': np.abs(coefs)\n",
    "})\n",
    "\n",
    "# 5. Sort by absolute value\n",
    "importance_df = importance_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# 6. Print the ranked feature importances\n",
    "print(importance_df[['Feature', 'Coefficient', 'Abs_Coefficient']])\n",
    "\n",
    "# 7. (Optional) Plot top 20 feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(importance_df['Feature'][:20][::-1], importance_df['Abs_Coefficient'][:20][::-1])\n",
    "plt.xlabel('Absolute Coefficient (Importance)')\n",
    "plt.title('Top 20 Feature Importances (Logistic Regression)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88fc56d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained successfully.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.38      0.55    120581\n",
      "           1       0.20      1.00      0.33     18653\n",
      "\n",
      "    accuracy                           0.47    139234\n",
      "   macro avg       0.60      0.69      0.44    139234\n",
      "weighted avg       0.89      0.47      0.53    139234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# List of months for delinquency\n",
    "months = list(range(1, 37))\n",
    "\n",
    "# Base features (static loan + borrower features)\n",
    "static_cols = [\n",
    "    'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value',\n",
    "    'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score',\n",
    "    'insurance_percent', 'co-borrower_credit_score', 'insurance_type',\n",
    "    'Age', 'NumberOfDependents', 'Annual Income',\n",
    "]\n",
    "\n",
    "# Add one-hot encoded categorical feature columns\n",
    "for col in newmodel.columns:\n",
    "    if col.startswith(('financial_institution_', 'loan_purpose_', 'Gender_',\n",
    "                       'EmploymentStatus_', 'EducationLevel_')):\n",
    "        static_cols.append(col)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Filter dataset for loans with term 36 only\n",
    "newm_36 = newm[newm['Loan_Term'] == 36]\n",
    "\n",
    "# Loop through all rows in filtered dataset\n",
    "for idx, row in newm_36.iterrows():\n",
    "    for t in months:\n",
    "        cur_m = f\"m{t}\"\n",
    "        next_m = f\"m{t+1}\"\n",
    "        next_m_missing = f\"m{t+1}_missing\"\n",
    "\n",
    "        # Skip if next month is invalid or current/next values are -1\n",
    "        if next_m not in newmodel.columns:\n",
    "            continue\n",
    "        if row.get(next_m_missing, 1) == 1 or row.get(cur_m, -1) == -1 or row.get(next_m, -1) == -1:\n",
    "            continue\n",
    "\n",
    "        # Get delinquency history m1 to mt\n",
    "        m_features = [row.get(f\"m{i}\", -1) for i in range(1, t + 1)]\n",
    "\n",
    "        # Pad with -1 to reach length 36 (max months)\n",
    "        m_features += [-1] * (36 - len(m_features))\n",
    "\n",
    "        # Get static features\n",
    "        static_features = [row.get(feat, 0) for feat in static_cols]\n",
    "\n",
    "        # Final feature vector\n",
    "        X.append(m_features + static_features)\n",
    "        # Binary target: 0 = no delinquency, 1 = any delinquency\n",
    "        y.append(1 if row[next_m] > 0 else 0)\n",
    "\n",
    "# Convert to NumPy arrays and train model\n",
    "if X:\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        max_iter=5000,\n",
    "        class_weight='balanced',\n",
    "        solver='saga',\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"✅ Model trained successfully.\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "else:\n",
    "    print(\"❌ No valid training samples. Check mX/mX_missing logic.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6c3e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.13.0 sklearn-compat-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84dfb623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\kusha\\anaconda3\\envs\\myenv\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "721d5d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature and label arrays created.\n",
      "Total samples: 2321070\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[31mTypeError\u001b[39m: float() argument must be a string or a real number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# STEP 5: Scale features\u001b[39;00m\n\u001b[32m     56\u001b[39m scaler = StandardScaler()\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m X_train = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m X_test = scaler.transform(X_test)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# STEP 6: Handle class imbalance with SMOTE\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:894\u001b[39m, in \u001b[36mStandardScaler.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:930\u001b[39m, in \u001b[36mStandardScaler.partial_fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[32m    899\u001b[39m \n\u001b[32m    900\u001b[39m \u001b[33;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    927\u001b[39m \u001b[33;03m    Fitted scaler.\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    929\u001b[39m first_call = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    938\u001b[39m n_features = X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1053\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1058\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    837\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m     array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# STEP 1: Create mX_missing columns directly on newm\n",
    "for i in range(1, 38):\n",
    "    col = f'm{i}'\n",
    "    missing_col = f'm{i}_missing'\n",
    "    newm[missing_col] = newm[col].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# STEP 2: Prepare X and y\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Base features excluding mX and loan_id\n",
    "base_features = [col for col in newm.columns if not col.startswith('m') and col != 'loan_id']\n",
    "\n",
    "# Create features and target\n",
    "for index, row in newm.iterrows():\n",
    "    term = row['Loan_Term']\n",
    "    for i in range(1, term):\n",
    "        curr_month = f'm{i}'\n",
    "        next_month = f'm{i+1}'\n",
    "        next_missing = f'{next_month}_missing'\n",
    "\n",
    "        if next_month not in newm.columns or next_missing not in newm.columns:\n",
    "            continue\n",
    "\n",
    "        if row[next_missing] == 1:\n",
    "            continue  # Skip if next month's data is missing\n",
    "\n",
    "        feature_row = row[base_features].tolist()\n",
    "\n",
    "        # Add payment history up to month i\n",
    "        for j in range(1, i+1):\n",
    "            feature_row.append(row[f'm{j}'])\n",
    "\n",
    "        X.append(feature_row)\n",
    "        y.append(row[next_month])  # Target = delinquency in next month\n",
    "\n",
    "# STEP 3: Convert to arrays\n",
    "X = np.array(X, dtype=object)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"✅ Feature and label arrays created.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "# STEP 4: Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# STEP 5: Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# STEP 6: Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# STEP 7: Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=5000, solver='saga', penalty='l2', class_weight='balanced')\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# STEP 8: Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n✅ Model trained successfully.\\n\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad1c2102",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2437128,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m         y.append(\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m row[target_col] > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# Binary target\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Convert to NumPy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m X = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m y = np.array(y)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Binary classification dataset prepared.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2437128,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# STEP 1: Flag missing values for m1 to m37\n",
    "for i in range(1, 38):\n",
    "    col = f'm{i}'\n",
    "    missing_col = f'{col}_missing'\n",
    "    newm[missing_col] = newm[col].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# STEP 2: Build feature and label arrays\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Define static features to use for m1 prediction and all others\n",
    "static_features = ['borrower_credit_score', 'debt_to_income_ratio', 'loan_to_value', 'Annual Income', 'interest_rate']  # Update as per actual column names\n",
    "\n",
    "for index, row in newm.iterrows():\n",
    "    term = row['Loan_Term']\n",
    "\n",
    "    # 1. Predict m1 using only static features\n",
    "    if 'm1' in newm.columns and row['m1'] != -1:\n",
    "        X.append([row[feat] for feat in static_features])\n",
    "        y.append(1 if row['m1'] > 0 else 0)  # Binary target\n",
    "\n",
    "    # 2. Predict m2 to m_term using static + m1 to m(t-1)\n",
    "    for t in range(2, term + 1):\n",
    "        target_col = f'm{t}'\n",
    "        target_missing = f'{target_col}_missing'\n",
    "\n",
    "        if target_col not in newm.columns or row[target_missing] == 1:\n",
    "            continue\n",
    "\n",
    "        if any(row[f'm{j}'] == -1 for j in range(1, t)):\n",
    "            continue  # Skip if any prior month is missing\n",
    "\n",
    "        features = [row[feat] for feat in static_features]\n",
    "        for j in range(1, t):\n",
    "            features.append(row[f'm{j}'])\n",
    "\n",
    "        X.append(features)\n",
    "        y.append(1 if row[target_col] > 0 else 0)  # Binary target\n",
    "\n",
    "# Convert to NumPy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"✅ Binary classification dataset prepared.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "# STEP 3: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# STEP 4: Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# STEP 5: Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# STEP 6: Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000, solver='saga', class_weight='balanced')\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# STEP 7: Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n✅ Model trained and evaluated on binary delinquency.\\n\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc5b31bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2437128, 40)\n",
      "y shape: (2437128,)\n",
      "✅ Binary classification dataset prepared.\n",
      "Total samples: 2437128\n",
      "\n",
      "✅ Model trained and evaluated on binary delinquency.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.84    443174\n",
      "           1       0.20      0.61      0.30     44252\n",
      "\n",
      "    accuracy                           0.74    487426\n",
      "   macro avg       0.58      0.68      0.57    487426\n",
      "weighted avg       0.88      0.74      0.79    487426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# STEP 1: Flag missing values for m1 to m37\n",
    "for i in range(1, 38):\n",
    "    col = f'm{i}'\n",
    "    missing_col = f'{col}_missing'\n",
    "    newm[missing_col] = newm[col].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# STEP 2: Build feature and label arrays\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Define static features to use for m1 prediction and all others\n",
    "static_features = ['borrower_credit_score', 'debt_to_income_ratio', 'loan_to_value', 'Annual Income', 'interest_rate']  # Update as per actual column names\n",
    "\n",
    "for index, row in newm.iterrows():\n",
    "    term = row['Loan_Term']\n",
    "\n",
    "    # 1. Predict m1 using only static features\n",
    "    if 'm1' in newm.columns and row['m1'] != -1:\n",
    "        feature_row = [row[feat] for feat in static_features]\n",
    "        if len(feature_row) == len(static_features):  # Check if the length matches\n",
    "            X.append(feature_row)\n",
    "            y.append(1 if row['m1'] > 0 else 0)  # Binary target\n",
    "\n",
    "    # 2. Predict m2 to m_term using static + m1 to m(t-1)\n",
    "    for t in range(2, term + 1):\n",
    "        target_col = f'm{t}'\n",
    "        target_missing = f'{target_col}_missing'\n",
    "\n",
    "        if target_col not in newm.columns or row[target_missing] == 1:\n",
    "            continue\n",
    "\n",
    "        # Check if prior months are available\n",
    "        if any(row[f'm{j}'] == -1 for j in range(1, t)):\n",
    "            continue  # Skip if any prior month is missing\n",
    "\n",
    "        # Create feature set: static + prior months (m1 to m(t-1))\n",
    "        feature_row = [row[feat] for feat in static_features]\n",
    "        for j in range(1, t):\n",
    "            feature_row.append(row[f'm{j}'])\n",
    "\n",
    "        if len(feature_row) == len(static_features) + (t - 1):  # Ensure feature consistency\n",
    "            X.append(feature_row)\n",
    "            y.append(1 if row[target_col] > 0 else 0)  # Binary target\n",
    "\n",
    "# Ensure consistent length for all feature vectors\n",
    "max_length = max(len(row) for row in X)  # Find the max length of any feature vector\n",
    "\n",
    "# Pad shorter feature vectors with zeros\n",
    "X_padded = []\n",
    "for row in X:\n",
    "    padded_row = row + [0] * (max_length - len(row))  # Pad with zeros\n",
    "    X_padded.append(padded_row)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(X_padded)\n",
    "y = np.array(y)\n",
    "\n",
    "# Check if X and y are valid before continuing\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"✅ Binary classification dataset prepared.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "# STEP 3: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# STEP 4: Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# STEP 5: Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# STEP 6: Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000, solver='saga', class_weight='balanced')\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# STEP 7: Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n✅ Model trained and evaluated on binary delinquency.\\n\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0aad62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2437128,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     49\u001b[39m         y.append(\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m row[target_col] > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Convert to NumPy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m X = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m y = np.array(y)\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2437128,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "for i in range(1, 38):\n",
    "    col = f'm{i}'\n",
    "    missing_col = f'{col}_missing'\n",
    "    newm[missing_col] = newm[col].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "static_features = ['borrower_credit_score', 'debt_to_income_ratio', 'loan_to_value', 'Annual Income', 'interest_rate']  # Update as needed\n",
    "\n",
    "max_term = newm['Loan_Term'].max()\n",
    "\n",
    "for _, row in newm.iterrows():\n",
    "    term = row['Loan_Term']\n",
    "\n",
    "    \n",
    "    if 'm1' in newm.columns and row['m1'] != -1:\n",
    "        X.append([row[feat] for feat in static_features] + [0] * (max_term - 1))\n",
    "        y.append(1 if row['m1'] > 0 else 0)\n",
    "\n",
    "   \n",
    "    for t in range(2, term + 1):\n",
    "        target_col = f'm{t}'\n",
    "        target_missing = f'{target_col}_missing'\n",
    "\n",
    "        if target_col not in newm.columns or row[target_missing] == 1:\n",
    "            continue\n",
    "\n",
    "        if any(row[f'm{j}'] == -1 for j in range(1, t)):\n",
    "            continue\n",
    "\n",
    "        features = [row[feat] for feat in static_features]\n",
    "        for j in range(1, t):\n",
    "            features.append(row[f'm{j}'])\n",
    "        features += [0] * (max_term - (t - 1)) \n",
    "\n",
    "        X.append(features)\n",
    "        y.append(1 if row[target_col] > 0 else 0)\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"✅ Binary classification dataset prepared.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l2'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['saga']\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'l1_ratio': [0.5, 0.7, 0.9],\n",
    "        'solver': ['saga']\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=5000, class_weight='balanced'),\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='f1',\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n✅ Model trained and evaluated on binary delinquency.\\n\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a079c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2437128,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m         y.append(\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m row[target_col] > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Convert to NumPy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m X = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m y = np.array(y)\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2437128,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  \n",
    "\n",
    "\n",
    "for i in range(1, 38):\n",
    "    col = f'm{i}'\n",
    "    missing_col = f'{col}_missing'\n",
    "    newm[missing_col] = newm[col].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "static_features = ['borrower_credit_score', 'debt_to_income_ratio', 'loan_to_value', 'Annual Income', 'interest_rate']  # Update as needed\n",
    "max_term = newm['Loan_Term'].max()\n",
    "\n",
    "for _, row in newm.iterrows():\n",
    "    term = row['Loan_Term']\n",
    "\n",
    "   \n",
    "    if 'm1' in newm.columns and row['m1'] != -1:\n",
    "        features = [row[feat] for feat in static_features]\n",
    "        features += [0] * (max_term - 1)  \n",
    "        X.append(features)\n",
    "        y.append(1 if row['m1'] > 0 else 0)\n",
    "\n",
    "   \n",
    "    for t in range(2, term + 1):\n",
    "        target_col = f'm{t}'\n",
    "        target_missing = f'{target_col}_missing'\n",
    "\n",
    "        if target_col not in newm.columns or row[target_missing] == 1:\n",
    "            continue\n",
    "        if any(row[f'm{j}'] == -1 for j in range(1, t)):\n",
    "            continue\n",
    "\n",
    "        features = [row[feat] for feat in static_features]\n",
    "        for j in range(1, t):\n",
    "            features.append(row[f'm{j}'])\n",
    "        features += [0] * (max_term - (t - 1))  \n",
    "\n",
    "        X.append(features)\n",
    "        y.append(1 if row[target_col] > 0 else 0)\n",
    "\n",
    "\n",
    "X = np.array(X, dtype=float)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"✅ Binary classification dataset prepared.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l2'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': [None]  \n",
    "    },\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'l1_ratio': [0.5, 0.7, 0.9],\n",
    "        'solver': ['saga']\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=5000, class_weight='balanced'),\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='f1',\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n✅ Model trained and evaluated on binary delinquency.\\n\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faacd9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2437128, 41)\n",
      "y shape: (2437128,)\n",
      "✅ Binary classification dataset prepared.\n",
      "Total samples: 2437128\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1450] Insufficient system resources exist to complete the requested service",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[32m     78\u001b[39m param_grid = [\n\u001b[32m     79\u001b[39m     {\n\u001b[32m     80\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mpenalty\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     90\u001b[39m     }\n\u001b[32m     91\u001b[39m ]\n\u001b[32m     93\u001b[39m grid_search = GridSearchCV(LogisticRegression(max_iter=\u001b[32m5000\u001b[39m, class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     94\u001b[39m                            param_grid,\n\u001b[32m     95\u001b[39m                            cv=\u001b[32m5\u001b[39m,\n\u001b[32m     96\u001b[39m                            scoring=\u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     97\u001b[39m                            n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m best_model = grid_search.best_estimator_\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# STEP 7: Evaluation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kusha\\anaconda3\\envs\\myenv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: [WinError 1450] Insufficient system resources exist to complete the requested service"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "\n",
    "\n",
    "for i in range(1, 38):\n",
    "    col = f'm{i}'\n",
    "    missing_col = f'{col}_missing'\n",
    "    newm[missing_col] = newm[col].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "static_features = ['borrower_credit_score', 'debt_to_income_ratio', 'loan_to_value', 'Annual Income', 'interest_rate']  # Update as needed\n",
    "max_term = int(newm['Loan_Term'].max())\n",
    "\n",
    "for _, row in newm.iterrows():\n",
    "    term = int(row['Loan_Term'])\n",
    "\n",
    "   \n",
    "    if 'm1' in newm.columns and row['m1'] != -1:\n",
    "        features = [row[feat] for feat in static_features]\n",
    "        features += [0] * max_term  \n",
    "        X.append(features)\n",
    "        y.append(1 if row['m1'] > 0 else 0)\n",
    "\n",
    "    \n",
    "    for t in range(2, term + 1):\n",
    "        target_col = f'm{t}'\n",
    "        target_missing = f'{target_col}_missing'\n",
    "\n",
    "        if target_col not in newm.columns or row[target_missing] == 1:\n",
    "            continue\n",
    "        if any(row[f'm{j}'] == -1 for j in range(1, t)):\n",
    "            continue\n",
    "\n",
    "        features = [row[feat] for feat in static_features]\n",
    "        \n",
    "        for j in range(1, t):\n",
    "            features.append(row[f'm{j}'])\n",
    "        \n",
    "        features += [0] * (max_term - (t - 1))\n",
    "\n",
    "        X.append(features)\n",
    "        y.append(1 if row[target_col] > 0 else 0)\n",
    "\n",
    "\n",
    "X = np.array(X, dtype=float)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"✅ Binary classification dataset prepared.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l2'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': [None] \n",
    "    },\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'l1_ratio': [0.5, 0.7, 0.9],\n",
    "        'solver': ['saga']\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=5000, class_weight='balanced'),\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='f1',\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n✅ Model trained and evaluated on binary delinquency.\\n\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "273dd188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2437128, 41)\n",
      "y shape: (2437128,)\n",
      "✅ Binary classification dataset prepared.\n",
      "Total samples: 2437128\n",
      "\n",
      "✅ Model trained and evaluated on binary delinquency.\n",
      "\n",
      "Best Parameters: {'C': 1, 'l1_ratio': 0.9, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.84    443174\n",
      "           1       0.20      0.61      0.30     44252\n",
      "\n",
      "    accuracy                           0.74    487426\n",
      "   macro avg       0.58      0.68      0.57    487426\n",
      "weighted avg       0.88      0.74      0.79    487426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # Optional: suppress elasticnet warnings\n",
    "\n",
    "# STEP 1: Flag missing values for m1 to m37\n",
    "for i in range(1, 38):\n",
    "    col = f'm{i}'\n",
    "    missing_col = f'{col}_missing'\n",
    "    newm[missing_col] = newm[col].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# STEP 2: Build feature and label arrays\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Static features used to predict m1 and other months\n",
    "static_features = ['borrower_credit_score', 'debt_to_income_ratio', 'loan_to_value', 'Annual Income', 'interest_rate']  # Update as needed\n",
    "max_term = int(newm['Loan_Term'].max())\n",
    "\n",
    "for _, row in newm.iterrows():\n",
    "    term = int(row['Loan_Term'])\n",
    "\n",
    "    # Predict m1 using static features + all zeros for monthly history\n",
    "    if 'm1' in newm.columns and row['m1'] != -1:\n",
    "        features = [row[feat] for feat in static_features]\n",
    "        features += [0] * max_term  # Pad with max_term zeros\n",
    "        X.append(features)\n",
    "        y.append(1 if row['m1'] > 0 else 0)\n",
    "\n",
    "    # Predict m2 to m_term using static + past months + pad for remaining months\n",
    "    for t in range(2, term + 1):\n",
    "        target_col = f'm{t}'\n",
    "        target_missing = f'{target_col}_missing'\n",
    "\n",
    "        if target_col not in newm.columns or row[target_missing] == 1:\n",
    "            continue\n",
    "        if any(row[f'm{j}'] == -1 for j in range(1, t)):\n",
    "            continue\n",
    "\n",
    "        features = [row[feat] for feat in static_features]\n",
    "        # Add payment history up to month t-1\n",
    "        for j in range(1, t):\n",
    "            features.append(row[f'm{j}'])\n",
    "        # Pad remaining months\n",
    "        features += [0] * (max_term - (t - 1))\n",
    "\n",
    "        X.append(features)\n",
    "        y.append(1 if row[target_col] > 0 else 0)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(X, dtype=float)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"✅ Binary classification dataset prepared.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "# STEP 3: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# STEP 4: Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# STEP 5: SMOTE for imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# STEP 6: Logistic Regression with simplified GridSearchCV\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l2'],\n",
    "        'C': [0.1, 1],  # Fewer values\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': [None]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'C': [0.1, 1],  # Fewer values\n",
    "        'l1_ratio': [0.5, 0.9],\n",
    "        'solver': ['saga']\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(max_iter=5000, class_weight='balanced'),\n",
    "    param_grid,\n",
    "    cv=3,            # Fewer folds\n",
    "    scoring='f1',\n",
    "    n_jobs=1         # Reduced parallelism\n",
    ")\n",
    "\n",
    "# Optional: Use a smaller sample for grid search if you still face issues\n",
    "# sample_size = 100000\n",
    "# X_sample = X_train_res[:sample_size]\n",
    "# y_sample = y_train_res[:sample_size]\n",
    "# grid_search.fit(X_sample, y_sample)\n",
    "\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# STEP 7: Evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n✅ Model trained and evaluated on binary delinquency.\\n\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "badf7cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2437128, 40)\n",
      "y shape: (2437128,)\n",
      "✅ Binary classification dataset prepared.\n",
      "Total samples: 2437128\n",
      "\n",
      "✅ Model trained and evaluated on binary delinquency.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.84    443174\n",
      "           1       0.20      0.61      0.30     44252\n",
      "\n",
      "    accuracy                           0.74    487426\n",
      "   macro avg       0.58      0.68      0.57    487426\n",
      "weighted avg       0.88      0.74      0.79    487426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n",
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26548\\1284697019.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  newm[pred_col] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Updated dataset with predictions saved as 'updated_loan_dataset_with_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assume newm is your original DataFrame loaded previously\n",
    "# newm = pd.read_csv('your_input_file.csv')\n",
    "\n",
    "# STEP 1: Flag missing values for m1 to m37\n",
    "for i in range(1, 38):\n",
    "    col = f'm{i}'\n",
    "    missing_col = f'{col}_missing'\n",
    "    newm[missing_col] = newm[col].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# STEP 2: Build feature and label arrays and track sample info\n",
    "X = []\n",
    "y = []\n",
    "sample_info = []  # To track (row index, month) for each sample\n",
    "\n",
    "static_features = ['borrower_credit_score', 'debt_to_income_ratio', 'loan_to_value', 'Annual Income', 'interest_rate']  # Update as per your columns\n",
    "\n",
    "for index, row in newm.iterrows():\n",
    "    term = row['Loan_Term']\n",
    "\n",
    "    # 1. Predict m1 using only static features\n",
    "    if 'm1' in newm.columns and row['m1'] != -1:\n",
    "        feature_row = [row[feat] for feat in static_features]\n",
    "        if len(feature_row) == len(static_features):\n",
    "            X.append(feature_row)\n",
    "            y.append(1 if row['m1'] > 0 else 0)\n",
    "            sample_info.append((index, 1))\n",
    "\n",
    "    # 2. Predict m2 to m_term using static + m1 to m(t-1)\n",
    "    for t in range(2, term + 1):\n",
    "        target_col = f'm{t}'\n",
    "        target_missing = f'{target_col}_missing'\n",
    "\n",
    "        if target_col not in newm.columns or row[target_missing] == 1:\n",
    "            continue\n",
    "\n",
    "        if any(row[f'm{j}'] == -1 for j in range(1, t)):\n",
    "            continue\n",
    "\n",
    "        feature_row = [row[feat] for feat in static_features]\n",
    "        for j in range(1, t):\n",
    "            feature_row.append(row[f'm{j}'])\n",
    "\n",
    "        if len(feature_row) == len(static_features) + (t - 1):\n",
    "            X.append(feature_row)\n",
    "            y.append(1 if row[target_col] > 0 else 0)\n",
    "            sample_info.append((index, t))\n",
    "\n",
    "# Ensure consistent length for all feature vectors\n",
    "max_length = max(len(row) for row in X)\n",
    "X_padded = []\n",
    "for row in X:\n",
    "    padded_row = row + [0] * (max_length - len(row))\n",
    "    X_padded.append(padded_row)\n",
    "\n",
    "X = np.array(X_padded)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"✅ Binary classification dataset prepared.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "# STEP 3: Train-test split (also split sample_info)\n",
    "X_train, X_test, y_train, y_test, info_train, info_test = train_test_split(\n",
    "    X, y, sample_info, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# STEP 4: Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# STEP 5: Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# STEP 6: Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000, solver='saga', class_weight='balanced')\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# STEP 7: Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n✅ Model trained and evaluated on binary delinquency.\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# STEP 8: Map predictions back to original DataFrame and save\n",
    "\n",
    "# Build a DataFrame of predictions with row index and month\n",
    "pred_df = pd.DataFrame(info_test, columns=['row_index', 'month'])\n",
    "pred_df['actual'] = y_test\n",
    "pred_df['predicted'] = y_pred\n",
    "\n",
    "# Add prediction columns to the original DataFrame\n",
    "for _, row in pred_df.iterrows():\n",
    "    idx = row['row_index']\n",
    "    month = row['month']\n",
    "    pred_col = f'm{month}_predicted'\n",
    "    if pred_col not in newm.columns:\n",
    "        newm[pred_col] = np.nan\n",
    "    newm.at[idx, pred_col] = row['predicted']\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "newm.to_csv('updated_loan_dataset_with_predictions.csv', index=False)\n",
    "print(\"\\n✅ Updated dataset with predictions saved as 'updated_loan_dataset_with_predictions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b47f1de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_id', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'insurance_percent', 'co-borrower_credit_score',\n",
      "       ...\n",
      "       'm16_predicted', 'm28_predicted', 'm35_predicted', 'm11_predicted', 'm34_predicted', 'm21_predicted', 'm25_predicted', 'm29_predicted', 'm32_predicted', 'm31_predicted'], dtype='object', length=161)\n"
     ]
    }
   ],
   "source": [
    "print(newm.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a18627bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_id', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'insurance_percent', 'co-borrower_credit_score',\n",
      "       ...\n",
      "       'EducationLevel_High School', 'EducationLevel_Master's', 'EducationLevel_PhD', 'origination_date_year', 'origination_date_month', 'origination_date_day', 'first_payment_date_year', 'first_payment_date_month', 'first_payment_date_day', 'days_to_first_payment'], dtype='object', length=125)\n"
     ]
    }
   ],
   "source": [
    "print(df_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ce0bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c9e7427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_id', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'insurance_percent', 'co-borrower_credit_score',\n",
      "       ...\n",
      "       'EducationLevel_High School', 'EducationLevel_Master's', 'EducationLevel_PhD', 'origination_date_year', 'origination_date_month', 'origination_date_day', 'first_payment_date_year', 'first_payment_date_month', 'first_payment_date_day', 'days_to_first_payment'], dtype='object', length=125)\n"
     ]
    }
   ],
   "source": [
    "print(model.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4d2577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4619179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2437128, 40)\n",
      "y shape: (2437128,)\n",
      "✅ Binary classification dataset prepared.\n",
      "Total samples: 2437128\n",
      "\n",
      "✅ Model trained and evaluated on binary delinquency.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.84    443174\n",
      "           1       0.20      0.61      0.30     44252\n",
      "\n",
      "    accuracy                           0.74    487426\n",
      "   macro avg       0.58      0.68      0.57    487426\n",
      "weighted avg       0.88      0.74      0.79    487426\n",
      "\n",
      "\n",
      "✅ Updated dataset with predictions saved as 'updated_loan_dataset_with_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "sample_info = []\n",
    "\n",
    "\n",
    "static_features = ['borrower_credit_score', 'debt_to_income_ratio', 'loan_to_value', 'Annual Income', 'interest_rate']\n",
    "\n",
    "for index, row in modell.iterrows():\n",
    "    term = int(row['Loan_Term'])\n",
    "    features = [row[feat] for feat in static_features]\n",
    "    for t in range(1, term + 1):\n",
    "       \n",
    "        if row[f'm{t}_missing'] == 1:\n",
    "            break  \n",
    "        \n",
    "        if t == 1:\n",
    "            feature_row = features.copy()\n",
    "        else:\n",
    "            feature_row = features + [row[f'm{j}'] for j in range(1, t)]\n",
    "        X.append(feature_row)\n",
    "        y.append(1 if row[f'm{t}'] > 0 else 0)\n",
    "        sample_info.append((index, t))\n",
    "\n",
    "\n",
    "max_length = max(len(row) for row in X)\n",
    "X_padded = []\n",
    "for row in X:\n",
    "    padded_row = row + [0] * (max_length - len(row))\n",
    "    X_padded.append(padded_row)\n",
    "\n",
    "X = np.array(X_padded)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"✅ Binary classification dataset prepared.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, info_train, info_test = train_test_split(\n",
    "    X, y, sample_info, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=5000, solver='saga', class_weight='balanced')\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n✅ Model trained and evaluated on binary delinquency.\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame(info_test, columns=['row_index', 'month'])\n",
    "pred_df['actual'] = y_test\n",
    "pred_df['predicted'] = y_pred\n",
    "\n",
    "for _, row in pred_df.iterrows():\n",
    "    idx = row['row_index']\n",
    "    month = row['month']\n",
    "    pred_col = f'm{month}_predicted'\n",
    "    if pred_col not in newm.columns:\n",
    "        newm[pred_col] = np.nan\n",
    "    newm.at[idx, pred_col] = row['predicted']\n",
    "\n",
    "newm.to_csv('updated_loan_dataset_with_predictions.csv', index=False)\n",
    "print(\"\\n✅ Updated dataset with predictions saved as 'updated_loan_dataset_with_predictions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7e5a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7c592db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_id', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'insurance_percent', 'co-borrower_credit_score',\n",
      "       ...\n",
      "       'EducationLevel_High School', 'EducationLevel_Master's', 'EducationLevel_PhD', 'origination_date_year', 'origination_date_month', 'origination_date_day', 'first_payment_date_year', 'first_payment_date_month', 'first_payment_date_day', 'days_to_first_payment'], dtype='object', length=125)\n"
     ]
    }
   ],
   "source": [
    "print(model.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "301f0b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (116058, 9)\n",
      "y shape: (116058,)\n",
      "✅ Binary classification dataset for m5 prepared.\n",
      "Total samples: 116058\n",
      "\n",
      "✅ Model trained and evaluated on m5 delinquency.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     23147\n",
      "           1       0.19      0.48      0.27        65\n",
      "\n",
      "    accuracy                           0.99     23212\n",
      "   macro avg       0.60      0.74      0.64     23212\n",
      "weighted avg       1.00      0.99      0.99     23212\n",
      "\n",
      "\n",
      "✅ Updated dataset with m5 predictions saved as 'updated_loan_dataset_with_m5_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assume newm is your DataFrame and mX_missing columns already exist\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "sample_info = []\n",
    "\n",
    "# Update according to your actual static feature columns\n",
    "static_features = ['borrower_credit_score', 'debt_to_income_ratio', 'loan_to_value', 'Annual Income', 'interest_rate']\n",
    "\n",
    "for index, row in model.iterrows():\n",
    "    # Only consider loans that have at least 5 months (m5 exists)\n",
    "    if f'm5' not in row or f'm5_missing' not in row:\n",
    "        continue\n",
    "    # Check if m1 to m5 are all present (not missing)\n",
    "    if any(row.get(f'm{i}_missing', 1) == 1 for i in range(1, 6)):\n",
    "        continue\n",
    "    # Build feature row: static + m1, m2, m3, m4\n",
    "    feature_row = [row[feat] for feat in static_features]\n",
    "    feature_row += [row[f'm{i}'] for i in range(1, 5)]\n",
    "    X.append(feature_row)\n",
    "    y.append(1 if row['m5'] > 0 else 0)\n",
    "    sample_info.append(index)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"✅ Binary classification dataset for m5 prepared.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "# Train-test split (also split sample_info)\n",
    "X_train, X_test, y_train, y_test, info_train, info_test = train_test_split(\n",
    "    X, y, sample_info, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000, solver='saga', class_weight='balanced')\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n✅ Model trained and evaluated on m5 delinquency.\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Map predictions back to original DataFrame and save\n",
    "for idx, pred in zip(info_test, y_pred):\n",
    "    if 'm5_predicted' not in newm.columns:\n",
    "        newm['m5_predicted'] = np.nan\n",
    "    newm.at[idx, 'm5_predicted'] = pred\n",
    "\n",
    "newm.to_csv('updated_loan_dataset_with_m5_predictions.csv', index=False)\n",
    "print(\"\\n✅ Updated dataset with m5 predictions saved as 'updated_loan_dataset_with_m5_predictions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "549db652",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m newm = \u001b[43mdf_copy\u001b[49m.copy()\n",
      "\u001b[31mNameError\u001b[39m: name 'df_copy' is not defined"
     ]
    }
   ],
   "source": [
    "newm = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3104a18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_id', 'interest_rate', 'unpaid_principal_bal', 'Loan_Term', 'loan_to_value', 'number_of_borrowers', 'debt_to_income_ratio', 'borrower_credit_score', 'insurance_percent', 'co-borrower_credit_score',\n",
      "       ...\n",
      "       'EducationLevel_High School', 'EducationLevel_Master's', 'EducationLevel_PhD', 'origination_date_year', 'origination_date_month', 'origination_date_day', 'first_payment_date_year', 'first_payment_date_month', 'first_payment_date_day', 'days_to_first_payment'], dtype='object', length=125)\n"
     ]
    }
   ],
   "source": [
    "print(newm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "52501aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (116058, 9)\n",
      "y shape: (116058,)\n",
      "✅ Binary classification dataset for m5 prepared.\n",
      "Total samples: 116058\n",
      "\n",
      "✅ Model trained and evaluated on m5 delinquency.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     23147\n",
      "           1       0.19      0.48      0.27        65\n",
      "\n",
      "    accuracy                           0.99     23212\n",
      "   macro avg       0.60      0.74      0.64     23212\n",
      "weighted avg       1.00      0.99      0.99     23212\n",
      "\n",
      "\n",
      "✅ Updated dataset with m5 predictions saved as 'updated_loan_dataset_with_m5_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assume newm is your DataFrame and mX_missing columns already exist\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "sample_info = []\n",
    "\n",
    "# Update according to your actual static feature columns\n",
    "static_features = ['borrower_credit_score', 'debt_to_income_ratio', 'loan_to_value', 'Annual Income', 'interest_rate']\n",
    "\n",
    "for index, row in newm.iterrows():\n",
    "    # Only consider loans that have at least 5 months (m5 exists)\n",
    "    if f'm5' not in row or f'm5_missing' not in row:\n",
    "        continue\n",
    "    # Check if m1 to m5 are all present (not missing)\n",
    "    if any(row.get(f'm{i}_missing', 1) == 1 for i in range(1, 6)):\n",
    "        continue\n",
    "    # Build feature row: static + m1, m2, m3, m4\n",
    "    feature_row = [row[feat] for feat in static_features]\n",
    "    feature_row += [row[f'm{i}'] for i in range(1, 5)]\n",
    "    X.append(feature_row)\n",
    "    y.append(1 if row['m5'] > 0 else 0)\n",
    "    sample_info.append(index)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(\"✅ Binary classification dataset for m5 prepared.\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "\n",
    "# Train-test split (also split sample_info)\n",
    "X_train, X_test, y_train, y_test, info_train, info_test = train_test_split(\n",
    "    X, y, sample_info, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000, solver='saga', class_weight='balanced')\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n✅ Model trained and evaluated on m5 delinquency.\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Map predictions back to original DataFrame and save\n",
    "for idx, pred in zip(info_test, y_pred):\n",
    "    if 'm5_predicted' not in newm.columns:\n",
    "        newm['m5_predicted'] = np.nan\n",
    "    newm.at[idx, 'm5_predicted'] = pred\n",
    "\n",
    "newm.to_csv('updated_loan_dataset_with_m5_predictions.csv', index=False)\n",
    "print(\"\\n✅ Updated dataset with m5 predictions saved as 'updated_loan_dataset_with_m5_predictions.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0e3b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'm1_60_40_split.csv' generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Total number of entries\n",
    "total_entries = 116059\n",
    "n_zeros = int(total_entries * 0.6)\n",
    "n_ones = total_entries - n_zeros\n",
    "\n",
    "# Generate values and shuffle\n",
    "values = [0] * n_zeros + [1] * n_ones\n",
    "np.random.shuffle(values)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df = pd.DataFrame({'m1': values})\n",
    "df.to_csv(\"m1_60_40_split.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'm1_60_40_split.csv' generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91d5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
